{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOJD0_jdzzg"
      },
      "source": [
        "## Computer vision 2022 Assignment 3: Deep Learning for Perception Tasks\n",
        "\n",
        "This assignment contains 2 questions. The first question gives you a basic understanding of the classifier. The second question requires you to write a simple proposal.\n",
        "\n",
        "# Question 1: A simple classifier (60%)\n",
        "\n",
        "For this exercise, we will provide a demo code showing how to train a network on a small dataset called FashionMinst. Please go through the following tutorials first. You will get a basic understanding about how to train an image classification network in pytorch. You can change the training scheme and the network structure. Please answer the following questions then. You can orginaze your own text and code cell to show the answer of each questions.\n",
        "\n",
        "\n",
        "Note: Please plot the loss curve for each experiment (2 point).\n",
        "\n",
        "\n",
        "Requirement:\n",
        "\n",
        "Q1.1 (1 point) Change the learning rate and train for 10 epochs. Fill this table:\n",
        "\n",
        "|Lr|Accuracy|\n",
        "|---|---|\n",
        "|1   |   19.92%   |\n",
        "|0.1|     87.22%     |\n",
        "|0.01|     83.67%    |\n",
        "|0.001  |    87.5%    |\n",
        "\n",
        "\n",
        "Q1.2 (2 point) Report the number of epochs when the accuracy reaches 90%. Fill this table:\n",
        "\n",
        "|Lr|Accuracy|Epoch|\n",
        "|---|---|---|\n",
        "|1   |   10%   |   11  |\n",
        "|0.1|     90%     |  174  |\n",
        "|0.01|    89.04%     |  273  |\n",
        "|0.001  |    87.2%    |   297  |\n",
        "\n",
        "\n",
        "Q1.3 (2 points) Compare the results in table 1 and table 2, what is your observation and your understanding of learning rate?\n",
        "\n",
        "\n",
        "\n",
        "Q1.4 (3 point) Build a deeper/ wider network. Report the accuracy and the parameters for each structure. Parameters represent the number of trainable parameters in your model, e.g. a 3 x 3 conv has 9 parameters.\n",
        "\n",
        "|Structures|Accuracy|Parameters|\n",
        "|---|---|---|\n",
        "|Base   |      ||\n",
        "|Deeper|          ||\n",
        "|Wider|         ||\n",
        "\n",
        "\n",
        "Q1.5 (2 points) Choose to do one of the following two tasks:\n",
        "\n",
        "a. Write a code to calculate the parameter and expian the code.\n",
        "\n",
        "OR\n",
        "\n",
        "b. Write done the process of how to calculate the parameters by hand. \n",
        "\n",
        "\n",
        "Q1.6 (1 points) What are your observations and conclusions for changing network structure?\n",
        "\n",
        "\n",
        "Q1.7 (2 points) Calculate the mean of the gradients of the loss to all trainable parameters. Plot the gradients curve for the first 100 training steps. What are your observations? Note that this gradients will be saved with the training weight automatically after you call loss.backwards(). Hint: the mean of the gradients should be decreased.\n",
        "\n",
        "For more exlanation of q1.7, you could refer to the following simple instructions: https://colab.research.google.com/drive/1XAsyNegGSvMf3_B6MrsXht7-fHqtJ7OW?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-sqkIpLjpVsh"
      },
      "outputs": [],
      "source": [
        "import numpy as np # This is for mathematical operations\n",
        "\n",
        "# this is used in plotting \n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "from a3 import *\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiaolinzzz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/malujie/Computer-vision/assignment 3/wandb/run-20220510_011147-39n9tgqr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/xiaolinzzz/Assignment%203/runs/39n9tgqr\" target=\"_blank\">tough-forest-16</a></strong> to <a href=\"https://wandb.ai/xiaolinzzz/Assignment%203\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/xiaolinzzz/Assignment%203/runs/39n9tgqr?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc1813fedf0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"Assignment 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "1wy3xhEx_x-1"
      },
      "outputs": [],
      "source": [
        "#### Tutorial Code\n",
        "####PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset. \n",
        "#####Dataset stores samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download training data from open datasets. \n",
        "##Every TorchVision Dataset includes two arguments: \n",
        "##transform and target_transform to modify the samples and labels respectively.\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNI4IusI_1ol"
      },
      "source": [
        "We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset and supports automatic batching, sampling, shuffling, and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "nQZ5l5Zs_4C3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "wandb.log({'batch_size': batch_size})\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtCU2LO_9Dk"
      },
      "source": [
        "To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the init function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "TRSp7pd3_6bS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn, optimizer = adam_optimizer(model, lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFZYEHY7ADvS"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "mJLACDm9AKxv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.310199  [    0/60000]\n",
            "loss: 2.282331  [ 6400/60000]\n",
            "loss: 2.331312  [12800/60000]\n",
            "loss: 2.297781  [19200/60000]\n",
            "loss: 2.282552  [25600/60000]\n",
            "loss: 2.321892  [32000/60000]\n",
            "loss: 2.309579  [38400/60000]\n",
            "loss: 2.293917  [44800/60000]\n",
            "loss: 2.304989  [51200/60000]\n",
            "loss: 2.327326  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.311613 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.331967  [    0/60000]\n",
            "loss: 2.298975  [ 6400/60000]\n",
            "loss: 2.326617  [12800/60000]\n",
            "loss: 2.293852  [19200/60000]\n",
            "loss: 2.279311  [25600/60000]\n",
            "loss: 2.318151  [32000/60000]\n",
            "loss: 2.309851  [38400/60000]\n",
            "loss: 2.288549  [44800/60000]\n",
            "loss: 2.306316  [51200/60000]\n",
            "loss: 2.328063  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.312076 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.334629  [    0/60000]\n",
            "loss: 2.300128  [ 6400/60000]\n",
            "loss: 2.326851  [12800/60000]\n",
            "loss: 2.294103  [19200/60000]\n",
            "loss: 2.277655  [25600/60000]\n",
            "loss: 2.316864  [32000/60000]\n",
            "loss: 2.309660  [38400/60000]\n",
            "loss: 2.293908  [44800/60000]\n",
            "loss: 2.306714  [51200/60000]\n",
            "loss: 2.328320  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.312392 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.335643  [    0/60000]\n",
            "loss: 2.300541  [ 6400/60000]\n",
            "loss: 2.326903  [12800/60000]\n",
            "loss: 2.294237  [19200/60000]\n",
            "loss: 2.277352  [25600/60000]\n",
            "loss: 2.316419  [32000/60000]\n",
            "loss: 2.309583  [38400/60000]\n",
            "loss: 2.293827  [44800/60000]\n",
            "loss: 2.306832  [51200/60000]\n",
            "loss: 2.328415  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.312502 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.335995  [    0/60000]\n",
            "loss: 2.300684  [ 6400/60000]\n",
            "loss: 2.326917  [12800/60000]\n",
            "loss: 2.294292  [19200/60000]\n",
            "loss: 2.277252  [25600/60000]\n",
            "loss: 2.316262  [32000/60000]\n",
            "loss: 2.309555  [38400/60000]\n",
            "loss: 2.293797  [44800/60000]\n",
            "loss: 2.306873  [51200/60000]\n",
            "loss: 2.328450  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.312541 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.336122  [    0/60000]\n",
            "loss: 2.300735  [ 6400/60000]\n",
            "loss: 2.326920  [12800/60000]\n",
            "loss: 2.294313  [19200/60000]\n",
            "loss: 2.277217  [25600/60000]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/malujie/Computer-vision/assignment 3/a3.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malujie/Computer-vision/assignment%203/a3.ipynb#ch0000014?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malujie/Computer-vision/assignment%203/a3.ipynb#ch0000014?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/malujie/Computer-vision/assignment%203/a3.ipynb#ch0000014?line=4'>5</a>\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malujie/Computer-vision/assignment%203/a3.ipynb#ch0000014?line=5'>6</a>\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malujie/Computer-vision/assignment%203/a3.ipynb#ch0000014?line=7'>8</a>\u001b[0m     loss \u001b[39m=\u001b[39m get_loss(test_dataloader, model, loss_fn)\n",
            "File \u001b[0;32m~/Computer-vision/assignment 3/a3.py:46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/malujie/Computer-vision/assignment%203/a3.py?line=43'>44</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/malujie/Computer-vision/assignment%203/a3.py?line=44'>45</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///Users/malujie/Computer-vision/assignment%203/a3.py?line=45'>46</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///Users/malujie/Computer-vision/assignment%203/a3.py?line=46'>47</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='file:///Users/malujie/Computer-vision/assignment%203/a3.py?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Train and test the model\n",
        "epochs = 300\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "    \n",
        "    loss = get_loss(test_dataloader, model, loss_fn)\n",
        "    acc = get_score(test_dataloader, model, loss_fn)\n",
        "    wandb.log({'accuracy': acc, 'Avg loss': loss})\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "run = api.run(path_lr_001_sgd)\n",
        "run.summary['epochs'] = 300\n",
        "run.summary[\"batch_size\"] = 64\n",
        "run.summary['optimizer'] = 'SGD'\n",
        "run.summary['learning_rate'] = 0.01\n",
        "run.summary['model'] = 'Base'\n",
        "run.summary.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "run = api.run(path_lr_01_sgd)\n",
        "run.summary['epochs'] = 300\n",
        "run.summary[\"batch_size\"] = 64\n",
        "run.summary['optimizer'] = 'SGD'\n",
        "run.summary['learning_rate'] = 0.1\n",
        "run.summary['model'] = 'Base'\n",
        "run.summary.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "run = api.run(path_lr_1_sgd)\n",
        "run.summary['epochs'] = 109\n",
        "run.summary[\"batch_size\"] = 64\n",
        "run.summary['optimizer'] = 'SGD'\n",
        "run.summary['learning_rate'] = 1\n",
        "run.summary['model'] = 'Base'\n",
        "run.summary.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "run = api.run(path_lr_0001_adam)\n",
        "run.summary['epochs'] = 300\n",
        "run.summary[\"batch_size\"] = 64\n",
        "run.summary['optimizer'] = 'Adam'\n",
        "run.summary['learning_rate'] = 0.001\n",
        "run.summary['model'] = 'Base'\n",
        "run.summary.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "api = wandb.Api()\n",
        "run = api.run(path_lr_0001_adam)\n",
        "run.config['optimizer'] = 'Adam'\n",
        "run.config['model'] = 'Base'\n",
        "run.config['learning_rate'] = 0.001\n",
        "run.config[\"batch_size\"] = 64\n",
        "run.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "run = api.run(path_lr_1_sgd)\n",
        "run.config['optimizer'] = 'SGD'\n",
        "run.config['model'] = 'Base'\n",
        "run.config['learning_rate'] = 0.01\n",
        "run.config[\"batch_size\"] = 64\n",
        "run.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S16_96RS3O1H"
      },
      "source": [
        "# Question 2: Proposal for Practical Applications (40%)\n",
        "Look for a typical computer vision problem, such as:\n",
        "a. removing noise on the image\n",
        "\n",
        "b. increasing the resolution of the image\n",
        "\n",
        "c. identifying objects in the image\n",
        "\n",
        "d. segmenting the area to which the image belongs\n",
        "\n",
        "e. estimating the depth of an object\n",
        "\n",
        "f. estimating the motion of two object in different frames\n",
        "\n",
        "h. others\n",
        "\n",
        "Discuss possible applications of this problem in life, e.g. image editing systems in your phone, improved quality of the old film, sweeping robot avoiding obstacles, unlocks the face of the mobile phone, identifies the cancer area according to the medical scan image, determines the identity according to the face, identifies the trash can on the road, and the detection system tracks the target object, etc.\n",
        "\n",
        "In this question, you need to do\n",
        "1. Clearly define the problem and describe its application scenarios\n",
        "2. Briefly describe a feasible solution based on image processing and traditional machine learning algorithms.\n",
        "3. Briefly describe a feasible deep learning-based solution.\n",
        "4. Compare the advantages and disadvantages of the two options.\n",
        "\n",
        "Hint1: Submit an individua report for question 2.\n",
        "\n",
        "Hint2: Well orginaze your report.\n",
        "\n",
        "Hint3: You can draw flow chart or inculde other figures for better understanding of your solution.  \n",
        "\n",
        "Please restrict your report within 800 words. In this question, you do not need to implement your solution. You only need to write down a proposal. Please submit this report in a seperate pdf. \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "a3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
