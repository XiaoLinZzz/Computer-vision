{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOJD0_jdzzg"
      },
      "source": [
        "## Computer vision 2022 Assignment 3: Deep Learning for Perception Tasks\n",
        "\n",
        "This assignment contains 2 questions. The first question gives you a basic understanding of the classifier. The second question requires you to write a simple proposal.\n",
        "\n",
        "# Question 1: A simple classifier (60%)\n",
        "\n",
        "For this exercise, we will provide a demo code showing how to train a network on a small dataset called FashionMinst. Please go through the following tutorials first. You will get a basic understanding about how to train an image classification network in pytorch. You can change the training scheme and the network structure. Please answer the following questions then. You can orginaze your own text and code cell to show the answer of each questions.\n",
        "\n",
        "\n",
        "Note: Please plot the loss curve for each experiment (2 point).\n",
        "\n",
        "\n",
        "Requirement:\n",
        "\n",
        "Q1.1 (1 point) Change the learning rate and train for 10 epochs. Fill this table:\n",
        "\n",
        "|Lr|Accuracy|\n",
        "|---|---|\n",
        "|1   |   19.92%   |\n",
        "|0.1|     87.22%     |\n",
        "|0.01|     83.67%    |\n",
        "|0.001  |    87.5%    |\n",
        "\n",
        "\n",
        "Q1.2 (2 point) Report the number of epochs when the accuracy reaches 90%. Fill this table:\n",
        "\n",
        "|Lr|Accuracy|Epoch|\n",
        "|---|---|---|\n",
        "|1   |   10%   |   11  |\n",
        "|0.1|     90%     |  174  |\n",
        "|0.01|    89.04%     |  273  |\n",
        "|0.001  |    87.2%    |   297  |\n",
        "\n",
        "\n",
        "Q1.3 (2 points) Compare the results in table 1 and table 2, what is your observation and your understanding of learning rate?\n",
        "\n",
        "From the table 1 and table 2, I notice that smaller learning rates necessitate more training epochs because of the fewer changes. On the other hand, larger learning rates result in faster changes.\n",
        "\n",
        "Q1.4 (3 point) Build a deeper/ wider network. Report the accuracy and the parameters for each structure. Parameters represent the number of trainable parameters in your model, e.g. a 3 x 3 conv has 9 parameters.\n",
        "\n",
        "|Structures|Accuracy|Parameters|\n",
        "|---|---|---|\n",
        "|Base   |   87.22%   |  669,706|\n",
        "|Deeper|  89.4%        |   674,836|\n",
        "|Wider|    90.3%     |   1,863,690|\n",
        "\n",
        "\n",
        "Q1.5 (2 points) Choose to do one of the following two tasks:\n",
        "\n",
        "a. Write a code to calculate the parameter and expian the code.\n",
        "\n",
        "OR\n",
        "\n",
        "b. Write done the process of how to calculate the parameters by hand. \n",
        "\n",
        "\n",
        "Q1.6 (1 points) What are your observations and conclusions for changing network structure?\n",
        "\n",
        "With the increasing of the parameters, the accuracy will also increase.\n",
        "\n",
        "Q1.7 (2 points) Calculate the mean of the gradients of the loss to all trainable parameters. Plot the gradients curve for the first 100 training steps. What are your observations? Note that this gradients will be saved with the training weight automatically after you call loss.backwards(). Hint: the mean of the gradients should be decreased.\n",
        "\n",
        "For more exlanation of q1.7, you could refer to the following simple instructions: https://colab.research.google.com/drive/1XAsyNegGSvMf3_B6MrsXht7-fHqtJ7OW?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-sqkIpLjpVsh"
      },
      "outputs": [],
      "source": [
        "import numpy as np # This is for mathematical operations\n",
        "\n",
        "# this is used in plotting \n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "from a3 import *\n",
        "from torchinfo import summary\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1wy3xhEx_x-1"
      },
      "outputs": [],
      "source": [
        "#### Tutorial Code\n",
        "####PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset. \n",
        "#####Dataset stores samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download training data from open datasets. \n",
        "##Every TorchVision Dataset includes two arguments: \n",
        "##transform and target_transform to modify the samples and labels respectively.\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNI4IusI_1ol"
      },
      "source": [
        "We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset and supports automatic batching, sampling, shuffling, and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nQZ5l5Zs_4C3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "# wandb.log({'batch_size': batch_size})\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtCU2LO_9Dk"
      },
      "source": [
        "To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the init function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TRSp7pd3_6bS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "NeuralNetwork                            --                        --\n",
              "├─Flatten: 1-1                           [1, 784]                  --\n",
              "├─Sequential: 1-2                        [1, 10]                   --\n",
              "│    └─Linear: 2-1                       [1, 512]                  401,920\n",
              "│    └─ReLU: 2-2                         [1, 512]                  --\n",
              "│    └─Linear: 2-3                       [1, 512]                  262,656\n",
              "│    └─ReLU: 2-4                         [1, 512]                  --\n",
              "│    └─Linear: 2-5                       [1, 10]                   5,130\n",
              "==========================================================================================\n",
              "Total params: 669,706\n",
              "Trainable params: 669,706\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.67\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.01\n",
              "Params size (MB): 2.68\n",
              "Estimated Total Size (MB): 2.69\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# Define model --> base\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "summary(model, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  401408\n",
            "     512\n",
            "  262144\n",
            "     512\n",
            "    5120\n",
            "      10\n",
            "________\n",
            "  669706\n"
          ]
        }
      ],
      "source": [
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "wider_model                              --                        --\n",
              "├─Flatten: 1-1                           [1, 784]                  --\n",
              "├─Sequential: 1-2                        [1, 10]                   --\n",
              "│    └─Linear: 2-1                       [1, 1024]                 803,840\n",
              "│    └─ReLU: 2-2                         [1, 1024]                 --\n",
              "│    └─Linear: 2-3                       [1, 1024]                 1,049,600\n",
              "│    └─ReLU: 2-4                         [1, 1024]                 --\n",
              "│    └─Linear: 2-5                       [1, 10]                   10,250\n",
              "==========================================================================================\n",
              "Total params: 1,863,690\n",
              "Trainable params: 1,863,690\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.86\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.02\n",
              "Params size (MB): 7.45\n",
              "Estimated Total Size (MB): 7.47\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a model --> wider\n",
        "# create a wider model\n",
        "class wider_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(wider_model, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "    \n",
        "wide_model = wider_model().to(device)\n",
        "summary(wide_model, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "deeper_model                             --\n",
              "├─Flatten: 1-1                           --\n",
              "├─Sequential: 1-2                        --\n",
              "│    └─Linear: 2-1                       401,920\n",
              "│    └─ReLU: 2-2                         --\n",
              "│    └─Linear: 2-3                       262,656\n",
              "│    └─ReLU: 2-4                         --\n",
              "│    └─Linear: 2-5                       5,130\n",
              "│    └─ReLU: 2-6                         --\n",
              "│    └─Linear: 2-7                       110\n",
              "=================================================================\n",
              "Total params: 669,816\n",
              "Trainable params: 669,816\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a model --> deeper\n",
        "# create a deeper model\n",
        "class deeper_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(deeper_model, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "    \n",
        "deep_model = deeper_model().to(device)\n",
        "summary(deep_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFZYEHY7ADvS"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "grads = []\n",
        "train_loss = []   \n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    loss_store = []\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # The gradients will be calculated after we call backwards.\n",
        "        val = []\n",
        "        for param in model.parameters():\n",
        "            val.append(param.detach().numpy())\n",
        "        for i in val:\n",
        "            temp = np.array(i)\n",
        "        grads.append(temp.mean())\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        # train_loss.append(loss.item())\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            loss_store.append(loss)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            \n",
        "    train_loss.append(np.mean(loss_store))\n",
        "\n",
        "acc = []\n",
        "test_loss_store = []\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    # store the loss\n",
        "    test_loss_store.append(test_loss)\n",
        "    correct /= size\n",
        "    acc.append(correct)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.313253  [    0/60000]\n",
            "loss: 2.161076  [ 6400/60000]\n",
            "loss: 1.783117  [12800/60000]\n",
            "loss: 1.493128  [19200/60000]\n",
            "loss: 1.151276  [25600/60000]\n",
            "loss: 1.036903  [32000/60000]\n",
            "loss: 1.009562  [38400/60000]\n",
            "loss: 0.865643  [44800/60000]\n",
            "loss: 0.875026  [51200/60000]\n",
            "loss: 0.812434  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.0%, Avg loss: 0.795387 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.804223  [    0/60000]\n",
            "loss: 0.860383  [ 6400/60000]\n",
            "loss: 0.591954  [12800/60000]\n",
            "loss: 0.789199  [19200/60000]\n",
            "loss: 0.678044  [25600/60000]\n",
            "loss: 0.635397  [32000/60000]\n",
            "loss: 0.715641  [38400/60000]\n",
            "loss: 0.684975  [44800/60000]\n",
            "loss: 0.708681  [51200/60000]\n",
            "loss: 0.642864  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 0.634583 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.576582  [    0/60000]\n",
            "loss: 0.667281  [ 6400/60000]\n",
            "loss: 0.445134  [12800/60000]\n",
            "loss: 0.676653  [19200/60000]\n",
            "loss: 0.595445  [25600/60000]\n",
            "loss: 0.557949  [32000/60000]\n",
            "loss: 0.595812  [38400/60000]\n",
            "loss: 0.644311  [44800/60000]\n",
            "loss: 0.675991  [51200/60000]\n",
            "loss: 0.552819  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 0.570316 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.482594  [    0/60000]\n",
            "loss: 0.574485  [ 6400/60000]\n",
            "loss: 0.384901  [12800/60000]\n",
            "loss: 0.613671  [19200/60000]\n",
            "loss: 0.540614  [25600/60000]\n",
            "loss: 0.518815  [32000/60000]\n",
            "loss: 0.540178  [38400/60000]\n",
            "loss: 0.643628  [44800/60000]\n",
            "loss: 0.660749  [51200/60000]\n",
            "loss: 0.489515  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.7%, Avg loss: 0.539526 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.426876  [    0/60000]\n",
            "loss: 0.525012  [ 6400/60000]\n",
            "loss: 0.350113  [12800/60000]\n",
            "loss: 0.571456  [19200/60000]\n",
            "loss: 0.496581  [25600/60000]\n",
            "loss: 0.488775  [32000/60000]\n",
            "loss: 0.509947  [38400/60000]\n",
            "loss: 0.638453  [44800/60000]\n",
            "loss: 0.638707  [51200/60000]\n",
            "loss: 0.451459  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.519336 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.386777  [    0/60000]\n",
            "loss: 0.496364  [ 6400/60000]\n",
            "loss: 0.326260  [12800/60000]\n",
            "loss: 0.541389  [19200/60000]\n",
            "loss: 0.466704  [25600/60000]\n",
            "loss: 0.466972  [32000/60000]\n",
            "loss: 0.489390  [38400/60000]\n",
            "loss: 0.624798  [44800/60000]\n",
            "loss: 0.617227  [51200/60000]\n",
            "loss: 0.429945  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 0.504481 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.356308  [    0/60000]\n",
            "loss: 0.477060  [ 6400/60000]\n",
            "loss: 0.307605  [12800/60000]\n",
            "loss: 0.520021  [19200/60000]\n",
            "loss: 0.443315  [25600/60000]\n",
            "loss: 0.451817  [32000/60000]\n",
            "loss: 0.471809  [38400/60000]\n",
            "loss: 0.609987  [44800/60000]\n",
            "loss: 0.598891  [51200/60000]\n",
            "loss: 0.416747  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.492856 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.334442  [    0/60000]\n",
            "loss: 0.461878  [ 6400/60000]\n",
            "loss: 0.293536  [12800/60000]\n",
            "loss: 0.503528  [19200/60000]\n",
            "loss: 0.424312  [25600/60000]\n",
            "loss: 0.441542  [32000/60000]\n",
            "loss: 0.457281  [38400/60000]\n",
            "loss: 0.594817  [44800/60000]\n",
            "loss: 0.585029  [51200/60000]\n",
            "loss: 0.407650  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.482932 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.318027  [    0/60000]\n",
            "loss: 0.447982  [ 6400/60000]\n",
            "loss: 0.281254  [12800/60000]\n",
            "loss: 0.489243  [19200/60000]\n",
            "loss: 0.408380  [25600/60000]\n",
            "loss: 0.432527  [32000/60000]\n",
            "loss: 0.442070  [38400/60000]\n",
            "loss: 0.581089  [44800/60000]\n",
            "loss: 0.571754  [51200/60000]\n",
            "loss: 0.402143  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.472463 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.304021  [    0/60000]\n",
            "loss: 0.435479  [ 6400/60000]\n",
            "loss: 0.271830  [12800/60000]\n",
            "loss: 0.476666  [19200/60000]\n",
            "loss: 0.392826  [25600/60000]\n",
            "loss: 0.422970  [32000/60000]\n",
            "loss: 0.428029  [38400/60000]\n",
            "loss: 0.570164  [44800/60000]\n",
            "loss: 0.559114  [51200/60000]\n",
            "loss: 0.397600  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.463324 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.293259  [    0/60000]\n",
            "loss: 0.424581  [ 6400/60000]\n",
            "loss: 0.263336  [12800/60000]\n",
            "loss: 0.465519  [19200/60000]\n",
            "loss: 0.379504  [25600/60000]\n",
            "loss: 0.414092  [32000/60000]\n",
            "loss: 0.415329  [38400/60000]\n",
            "loss: 0.558772  [44800/60000]\n",
            "loss: 0.548159  [51200/60000]\n",
            "loss: 0.393585  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.453839 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.284586  [    0/60000]\n",
            "loss: 0.414117  [ 6400/60000]\n",
            "loss: 0.256559  [12800/60000]\n",
            "loss: 0.455013  [19200/60000]\n",
            "loss: 0.368007  [25600/60000]\n",
            "loss: 0.405089  [32000/60000]\n",
            "loss: 0.404492  [38400/60000]\n",
            "loss: 0.547934  [44800/60000]\n",
            "loss: 0.540298  [51200/60000]\n",
            "loss: 0.390571  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.446468 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.277090  [    0/60000]\n",
            "loss: 0.403793  [ 6400/60000]\n",
            "loss: 0.251449  [12800/60000]\n",
            "loss: 0.443613  [19200/60000]\n",
            "loss: 0.357763  [25600/60000]\n",
            "loss: 0.399045  [32000/60000]\n",
            "loss: 0.394776  [38400/60000]\n",
            "loss: 0.538861  [44800/60000]\n",
            "loss: 0.531297  [51200/60000]\n",
            "loss: 0.386678  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.438618 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.269563  [    0/60000]\n",
            "loss: 0.395185  [ 6400/60000]\n",
            "loss: 0.246861  [12800/60000]\n",
            "loss: 0.433272  [19200/60000]\n",
            "loss: 0.348303  [25600/60000]\n",
            "loss: 0.393287  [32000/60000]\n",
            "loss: 0.385748  [38400/60000]\n",
            "loss: 0.530580  [44800/60000]\n",
            "loss: 0.522869  [51200/60000]\n",
            "loss: 0.383603  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.431924 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.262952  [    0/60000]\n",
            "loss: 0.387579  [ 6400/60000]\n",
            "loss: 0.243026  [12800/60000]\n",
            "loss: 0.424783  [19200/60000]\n",
            "loss: 0.338775  [25600/60000]\n",
            "loss: 0.388905  [32000/60000]\n",
            "loss: 0.376994  [38400/60000]\n",
            "loss: 0.520575  [44800/60000]\n",
            "loss: 0.515732  [51200/60000]\n",
            "loss: 0.381657  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.425285 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.257545  [    0/60000]\n",
            "loss: 0.380823  [ 6400/60000]\n",
            "loss: 0.239855  [12800/60000]\n",
            "loss: 0.415618  [19200/60000]\n",
            "loss: 0.331393  [25600/60000]\n",
            "loss: 0.384346  [32000/60000]\n",
            "loss: 0.368952  [38400/60000]\n",
            "loss: 0.512418  [44800/60000]\n",
            "loss: 0.507562  [51200/60000]\n",
            "loss: 0.378098  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.419053 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.250688  [    0/60000]\n",
            "loss: 0.375384  [ 6400/60000]\n",
            "loss: 0.237203  [12800/60000]\n",
            "loss: 0.406476  [19200/60000]\n",
            "loss: 0.324299  [25600/60000]\n",
            "loss: 0.379534  [32000/60000]\n",
            "loss: 0.361253  [38400/60000]\n",
            "loss: 0.506561  [44800/60000]\n",
            "loss: 0.499370  [51200/60000]\n",
            "loss: 0.374644  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.412933 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.244650  [    0/60000]\n",
            "loss: 0.370321  [ 6400/60000]\n",
            "loss: 0.234317  [12800/60000]\n",
            "loss: 0.399481  [19200/60000]\n",
            "loss: 0.319168  [25600/60000]\n",
            "loss: 0.373968  [32000/60000]\n",
            "loss: 0.356867  [38400/60000]\n",
            "loss: 0.500034  [44800/60000]\n",
            "loss: 0.491444  [51200/60000]\n",
            "loss: 0.371000  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.407930 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.238823  [    0/60000]\n",
            "loss: 0.364886  [ 6400/60000]\n",
            "loss: 0.231676  [12800/60000]\n",
            "loss: 0.392550  [19200/60000]\n",
            "loss: 0.313886  [25600/60000]\n",
            "loss: 0.369399  [32000/60000]\n",
            "loss: 0.353439  [38400/60000]\n",
            "loss: 0.492204  [44800/60000]\n",
            "loss: 0.485788  [51200/60000]\n",
            "loss: 0.368196  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.8%, Avg loss: 0.403743 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.233843  [    0/60000]\n",
            "loss: 0.359010  [ 6400/60000]\n",
            "loss: 0.229353  [12800/60000]\n",
            "loss: 0.385094  [19200/60000]\n",
            "loss: 0.310745  [25600/60000]\n",
            "loss: 0.366043  [32000/60000]\n",
            "loss: 0.348822  [38400/60000]\n",
            "loss: 0.485026  [44800/60000]\n",
            "loss: 0.479901  [51200/60000]\n",
            "loss: 0.366474  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.399216 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.227177  [    0/60000]\n",
            "loss: 0.353486  [ 6400/60000]\n",
            "loss: 0.226760  [12800/60000]\n",
            "loss: 0.378302  [19200/60000]\n",
            "loss: 0.306613  [25600/60000]\n",
            "loss: 0.362241  [32000/60000]\n",
            "loss: 0.343813  [38400/60000]\n",
            "loss: 0.478123  [44800/60000]\n",
            "loss: 0.472682  [51200/60000]\n",
            "loss: 0.364991  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.395520 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.223045  [    0/60000]\n",
            "loss: 0.348893  [ 6400/60000]\n",
            "loss: 0.224071  [12800/60000]\n",
            "loss: 0.371208  [19200/60000]\n",
            "loss: 0.303317  [25600/60000]\n",
            "loss: 0.357645  [32000/60000]\n",
            "loss: 0.340045  [38400/60000]\n",
            "loss: 0.471605  [44800/60000]\n",
            "loss: 0.467284  [51200/60000]\n",
            "loss: 0.363510  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.392319 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.218466  [    0/60000]\n",
            "loss: 0.344458  [ 6400/60000]\n",
            "loss: 0.221383  [12800/60000]\n",
            "loss: 0.364823  [19200/60000]\n",
            "loss: 0.299182  [25600/60000]\n",
            "loss: 0.352983  [32000/60000]\n",
            "loss: 0.337340  [38400/60000]\n",
            "loss: 0.465674  [44800/60000]\n",
            "loss: 0.461416  [51200/60000]\n",
            "loss: 0.362279  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.389123 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.214304  [    0/60000]\n",
            "loss: 0.340373  [ 6400/60000]\n",
            "loss: 0.218741  [12800/60000]\n",
            "loss: 0.358380  [19200/60000]\n",
            "loss: 0.296193  [25600/60000]\n",
            "loss: 0.349323  [32000/60000]\n",
            "loss: 0.333577  [38400/60000]\n",
            "loss: 0.458644  [44800/60000]\n",
            "loss: 0.456185  [51200/60000]\n",
            "loss: 0.359737  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.385806 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.210708  [    0/60000]\n",
            "loss: 0.335867  [ 6400/60000]\n",
            "loss: 0.216422  [12800/60000]\n",
            "loss: 0.352414  [19200/60000]\n",
            "loss: 0.293491  [25600/60000]\n",
            "loss: 0.346822  [32000/60000]\n",
            "loss: 0.328830  [38400/60000]\n",
            "loss: 0.452376  [44800/60000]\n",
            "loss: 0.450271  [51200/60000]\n",
            "loss: 0.357669  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.382509 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.206507  [    0/60000]\n",
            "loss: 0.331233  [ 6400/60000]\n",
            "loss: 0.213587  [12800/60000]\n",
            "loss: 0.346833  [19200/60000]\n",
            "loss: 0.291731  [25600/60000]\n",
            "loss: 0.342876  [32000/60000]\n",
            "loss: 0.326511  [38400/60000]\n",
            "loss: 0.446406  [44800/60000]\n",
            "loss: 0.444907  [51200/60000]\n",
            "loss: 0.354948  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.379582 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.203397  [    0/60000]\n",
            "loss: 0.326988  [ 6400/60000]\n",
            "loss: 0.211348  [12800/60000]\n",
            "loss: 0.340966  [19200/60000]\n",
            "loss: 0.289241  [25600/60000]\n",
            "loss: 0.338792  [32000/60000]\n",
            "loss: 0.322826  [38400/60000]\n",
            "loss: 0.440042  [44800/60000]\n",
            "loss: 0.440175  [51200/60000]\n",
            "loss: 0.353339  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.376482 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.199797  [    0/60000]\n",
            "loss: 0.322840  [ 6400/60000]\n",
            "loss: 0.209242  [12800/60000]\n",
            "loss: 0.335948  [19200/60000]\n",
            "loss: 0.287162  [25600/60000]\n",
            "loss: 0.335866  [32000/60000]\n",
            "loss: 0.319148  [38400/60000]\n",
            "loss: 0.433350  [44800/60000]\n",
            "loss: 0.434714  [51200/60000]\n",
            "loss: 0.351423  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.373633 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.197641  [    0/60000]\n",
            "loss: 0.318078  [ 6400/60000]\n",
            "loss: 0.207500  [12800/60000]\n",
            "loss: 0.330515  [19200/60000]\n",
            "loss: 0.285669  [25600/60000]\n",
            "loss: 0.332975  [32000/60000]\n",
            "loss: 0.316858  [38400/60000]\n",
            "loss: 0.426486  [44800/60000]\n",
            "loss: 0.431488  [51200/60000]\n",
            "loss: 0.348494  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.370918 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.196132  [    0/60000]\n",
            "loss: 0.314793  [ 6400/60000]\n",
            "loss: 0.205520  [12800/60000]\n",
            "loss: 0.324980  [19200/60000]\n",
            "loss: 0.284629  [25600/60000]\n",
            "loss: 0.330192  [32000/60000]\n",
            "loss: 0.314099  [38400/60000]\n",
            "loss: 0.418850  [44800/60000]\n",
            "loss: 0.422972  [51200/60000]\n",
            "loss: 0.345130  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.368148 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.193505  [    0/60000]\n",
            "loss: 0.310857  [ 6400/60000]\n",
            "loss: 0.203773  [12800/60000]\n",
            "loss: 0.320017  [19200/60000]\n",
            "loss: 0.283934  [25600/60000]\n",
            "loss: 0.326096  [32000/60000]\n",
            "loss: 0.311971  [38400/60000]\n",
            "loss: 0.412424  [44800/60000]\n",
            "loss: 0.418849  [51200/60000]\n",
            "loss: 0.344805  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.365627 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.190781  [    0/60000]\n",
            "loss: 0.307867  [ 6400/60000]\n",
            "loss: 0.200998  [12800/60000]\n",
            "loss: 0.314685  [19200/60000]\n",
            "loss: 0.283346  [25600/60000]\n",
            "loss: 0.322637  [32000/60000]\n",
            "loss: 0.309455  [38400/60000]\n",
            "loss: 0.404451  [44800/60000]\n",
            "loss: 0.413262  [51200/60000]\n",
            "loss: 0.343361  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.362990 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.187833  [    0/60000]\n",
            "loss: 0.303779  [ 6400/60000]\n",
            "loss: 0.198643  [12800/60000]\n",
            "loss: 0.309591  [19200/60000]\n",
            "loss: 0.281407  [25600/60000]\n",
            "loss: 0.319689  [32000/60000]\n",
            "loss: 0.306248  [38400/60000]\n",
            "loss: 0.397214  [44800/60000]\n",
            "loss: 0.407421  [51200/60000]\n",
            "loss: 0.341388  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.361414 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.186460  [    0/60000]\n",
            "loss: 0.300243  [ 6400/60000]\n",
            "loss: 0.197997  [12800/60000]\n",
            "loss: 0.305057  [19200/60000]\n",
            "loss: 0.280101  [25600/60000]\n",
            "loss: 0.317474  [32000/60000]\n",
            "loss: 0.303703  [38400/60000]\n",
            "loss: 0.389174  [44800/60000]\n",
            "loss: 0.403183  [51200/60000]\n",
            "loss: 0.340339  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.359483 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.185060  [    0/60000]\n",
            "loss: 0.297061  [ 6400/60000]\n",
            "loss: 0.195934  [12800/60000]\n",
            "loss: 0.301581  [19200/60000]\n",
            "loss: 0.277543  [25600/60000]\n",
            "loss: 0.315366  [32000/60000]\n",
            "loss: 0.300001  [38400/60000]\n",
            "loss: 0.383165  [44800/60000]\n",
            "loss: 0.397697  [51200/60000]\n",
            "loss: 0.338704  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.357157 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.184461  [    0/60000]\n",
            "loss: 0.293058  [ 6400/60000]\n",
            "loss: 0.193901  [12800/60000]\n",
            "loss: 0.296243  [19200/60000]\n",
            "loss: 0.277386  [25600/60000]\n",
            "loss: 0.313128  [32000/60000]\n",
            "loss: 0.297744  [38400/60000]\n",
            "loss: 0.376680  [44800/60000]\n",
            "loss: 0.394170  [51200/60000]\n",
            "loss: 0.337638  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.355599 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.182985  [    0/60000]\n",
            "loss: 0.290078  [ 6400/60000]\n",
            "loss: 0.192032  [12800/60000]\n",
            "loss: 0.293292  [19200/60000]\n",
            "loss: 0.277178  [25600/60000]\n",
            "loss: 0.310968  [32000/60000]\n",
            "loss: 0.295245  [38400/60000]\n",
            "loss: 0.369301  [44800/60000]\n",
            "loss: 0.386978  [51200/60000]\n",
            "loss: 0.334931  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.354002 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.180785  [    0/60000]\n",
            "loss: 0.287097  [ 6400/60000]\n",
            "loss: 0.189632  [12800/60000]\n",
            "loss: 0.288365  [19200/60000]\n",
            "loss: 0.276472  [25600/60000]\n",
            "loss: 0.308670  [32000/60000]\n",
            "loss: 0.292504  [38400/60000]\n",
            "loss: 0.362406  [44800/60000]\n",
            "loss: 0.384566  [51200/60000]\n",
            "loss: 0.333475  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.352522 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.180013  [    0/60000]\n",
            "loss: 0.283772  [ 6400/60000]\n",
            "loss: 0.188940  [12800/60000]\n",
            "loss: 0.284388  [19200/60000]\n",
            "loss: 0.276057  [25600/60000]\n",
            "loss: 0.305663  [32000/60000]\n",
            "loss: 0.289294  [38400/60000]\n",
            "loss: 0.357147  [44800/60000]\n",
            "loss: 0.379921  [51200/60000]\n",
            "loss: 0.332007  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.351381 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.178159  [    0/60000]\n",
            "loss: 0.279782  [ 6400/60000]\n",
            "loss: 0.185780  [12800/60000]\n",
            "loss: 0.279506  [19200/60000]\n",
            "loss: 0.274474  [25600/60000]\n",
            "loss: 0.303880  [32000/60000]\n",
            "loss: 0.284888  [38400/60000]\n",
            "loss: 0.349276  [44800/60000]\n",
            "loss: 0.374945  [51200/60000]\n",
            "loss: 0.331138  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.350171 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.177783  [    0/60000]\n",
            "loss: 0.277595  [ 6400/60000]\n",
            "loss: 0.185691  [12800/60000]\n",
            "loss: 0.275386  [19200/60000]\n",
            "loss: 0.273195  [25600/60000]\n",
            "loss: 0.301488  [32000/60000]\n",
            "loss: 0.282368  [38400/60000]\n",
            "loss: 0.342222  [44800/60000]\n",
            "loss: 0.369362  [51200/60000]\n",
            "loss: 0.329002  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.348900 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.177484  [    0/60000]\n",
            "loss: 0.273925  [ 6400/60000]\n",
            "loss: 0.183756  [12800/60000]\n",
            "loss: 0.270600  [19200/60000]\n",
            "loss: 0.271907  [25600/60000]\n",
            "loss: 0.299727  [32000/60000]\n",
            "loss: 0.279198  [38400/60000]\n",
            "loss: 0.335744  [44800/60000]\n",
            "loss: 0.364456  [51200/60000]\n",
            "loss: 0.326981  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.347985 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.176859  [    0/60000]\n",
            "loss: 0.269983  [ 6400/60000]\n",
            "loss: 0.181661  [12800/60000]\n",
            "loss: 0.266686  [19200/60000]\n",
            "loss: 0.270812  [25600/60000]\n",
            "loss: 0.298056  [32000/60000]\n",
            "loss: 0.276283  [38400/60000]\n",
            "loss: 0.328344  [44800/60000]\n",
            "loss: 0.361338  [51200/60000]\n",
            "loss: 0.325418  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.347072 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.176887  [    0/60000]\n",
            "loss: 0.268101  [ 6400/60000]\n",
            "loss: 0.181991  [12800/60000]\n",
            "loss: 0.263486  [19200/60000]\n",
            "loss: 0.268252  [25600/60000]\n",
            "loss: 0.298669  [32000/60000]\n",
            "loss: 0.273295  [38400/60000]\n",
            "loss: 0.323128  [44800/60000]\n",
            "loss: 0.356624  [51200/60000]\n",
            "loss: 0.323274  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.346055 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.175424  [    0/60000]\n",
            "loss: 0.264726  [ 6400/60000]\n",
            "loss: 0.181973  [12800/60000]\n",
            "loss: 0.260539  [19200/60000]\n",
            "loss: 0.268132  [25600/60000]\n",
            "loss: 0.295459  [32000/60000]\n",
            "loss: 0.268655  [38400/60000]\n",
            "loss: 0.316362  [44800/60000]\n",
            "loss: 0.351166  [51200/60000]\n",
            "loss: 0.321342  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.344588 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.174529  [    0/60000]\n",
            "loss: 0.261951  [ 6400/60000]\n",
            "loss: 0.178363  [12800/60000]\n",
            "loss: 0.255613  [19200/60000]\n",
            "loss: 0.266983  [25600/60000]\n",
            "loss: 0.292852  [32000/60000]\n",
            "loss: 0.265180  [38400/60000]\n",
            "loss: 0.309662  [44800/60000]\n",
            "loss: 0.347013  [51200/60000]\n",
            "loss: 0.319637  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.343917 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.174485  [    0/60000]\n",
            "loss: 0.258916  [ 6400/60000]\n",
            "loss: 0.177272  [12800/60000]\n",
            "loss: 0.254421  [19200/60000]\n",
            "loss: 0.263775  [25600/60000]\n",
            "loss: 0.294939  [32000/60000]\n",
            "loss: 0.263315  [38400/60000]\n",
            "loss: 0.304100  [44800/60000]\n",
            "loss: 0.343599  [51200/60000]\n",
            "loss: 0.316981  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.342214 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.173648  [    0/60000]\n",
            "loss: 0.256511  [ 6400/60000]\n",
            "loss: 0.174460  [12800/60000]\n",
            "loss: 0.250463  [19200/60000]\n",
            "loss: 0.261735  [25600/60000]\n",
            "loss: 0.293512  [32000/60000]\n",
            "loss: 0.260310  [38400/60000]\n",
            "loss: 0.296957  [44800/60000]\n",
            "loss: 0.340458  [51200/60000]\n",
            "loss: 0.313837  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.341050 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.170558  [    0/60000]\n",
            "loss: 0.254554  [ 6400/60000]\n",
            "loss: 0.174862  [12800/60000]\n",
            "loss: 0.247236  [19200/60000]\n",
            "loss: 0.261547  [25600/60000]\n",
            "loss: 0.290893  [32000/60000]\n",
            "loss: 0.255879  [38400/60000]\n",
            "loss: 0.292165  [44800/60000]\n",
            "loss: 0.336744  [51200/60000]\n",
            "loss: 0.311603  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.340580 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.171632  [    0/60000]\n",
            "loss: 0.251865  [ 6400/60000]\n",
            "loss: 0.172432  [12800/60000]\n",
            "loss: 0.244015  [19200/60000]\n",
            "loss: 0.261046  [25600/60000]\n",
            "loss: 0.289716  [32000/60000]\n",
            "loss: 0.252272  [38400/60000]\n",
            "loss: 0.286663  [44800/60000]\n",
            "loss: 0.332690  [51200/60000]\n",
            "loss: 0.309630  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.339738 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.171518  [    0/60000]\n",
            "loss: 0.248174  [ 6400/60000]\n",
            "loss: 0.170366  [12800/60000]\n",
            "loss: 0.239254  [19200/60000]\n",
            "loss: 0.259142  [25600/60000]\n",
            "loss: 0.287088  [32000/60000]\n",
            "loss: 0.250190  [38400/60000]\n",
            "loss: 0.280843  [44800/60000]\n",
            "loss: 0.328823  [51200/60000]\n",
            "loss: 0.307350  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.339167 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.172145  [    0/60000]\n",
            "loss: 0.245300  [ 6400/60000]\n",
            "loss: 0.170847  [12800/60000]\n",
            "loss: 0.234705  [19200/60000]\n",
            "loss: 0.257397  [25600/60000]\n",
            "loss: 0.287288  [32000/60000]\n",
            "loss: 0.246912  [38400/60000]\n",
            "loss: 0.276093  [44800/60000]\n",
            "loss: 0.325057  [51200/60000]\n",
            "loss: 0.304212  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.336817 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.173212  [    0/60000]\n",
            "loss: 0.242584  [ 6400/60000]\n",
            "loss: 0.168640  [12800/60000]\n",
            "loss: 0.231775  [19200/60000]\n",
            "loss: 0.256810  [25600/60000]\n",
            "loss: 0.287091  [32000/60000]\n",
            "loss: 0.243541  [38400/60000]\n",
            "loss: 0.270637  [44800/60000]\n",
            "loss: 0.322633  [51200/60000]\n",
            "loss: 0.301058  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.335846 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.167112  [    0/60000]\n",
            "loss: 0.237938  [ 6400/60000]\n",
            "loss: 0.168171  [12800/60000]\n",
            "loss: 0.229266  [19200/60000]\n",
            "loss: 0.255276  [25600/60000]\n",
            "loss: 0.284397  [32000/60000]\n",
            "loss: 0.239599  [38400/60000]\n",
            "loss: 0.263747  [44800/60000]\n",
            "loss: 0.318333  [51200/60000]\n",
            "loss: 0.296489  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.335689 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.168169  [    0/60000]\n",
            "loss: 0.235641  [ 6400/60000]\n",
            "loss: 0.167469  [12800/60000]\n",
            "loss: 0.226677  [19200/60000]\n",
            "loss: 0.251554  [25600/60000]\n",
            "loss: 0.283266  [32000/60000]\n",
            "loss: 0.236720  [38400/60000]\n",
            "loss: 0.259982  [44800/60000]\n",
            "loss: 0.315236  [51200/60000]\n",
            "loss: 0.295148  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.335872 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.170681  [    0/60000]\n",
            "loss: 0.233134  [ 6400/60000]\n",
            "loss: 0.165692  [12800/60000]\n",
            "loss: 0.222541  [19200/60000]\n",
            "loss: 0.249288  [25600/60000]\n",
            "loss: 0.280912  [32000/60000]\n",
            "loss: 0.233838  [38400/60000]\n",
            "loss: 0.256053  [44800/60000]\n",
            "loss: 0.312435  [51200/60000]\n",
            "loss: 0.289865  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.334626 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.171124  [    0/60000]\n",
            "loss: 0.230229  [ 6400/60000]\n",
            "loss: 0.163064  [12800/60000]\n",
            "loss: 0.220318  [19200/60000]\n",
            "loss: 0.247997  [25600/60000]\n",
            "loss: 0.280520  [32000/60000]\n",
            "loss: 0.229274  [38400/60000]\n",
            "loss: 0.251132  [44800/60000]\n",
            "loss: 0.309662  [51200/60000]\n",
            "loss: 0.285057  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.334105 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.171108  [    0/60000]\n",
            "loss: 0.229150  [ 6400/60000]\n",
            "loss: 0.160960  [12800/60000]\n",
            "loss: 0.216730  [19200/60000]\n",
            "loss: 0.247439  [25600/60000]\n",
            "loss: 0.279509  [32000/60000]\n",
            "loss: 0.226799  [38400/60000]\n",
            "loss: 0.246411  [44800/60000]\n",
            "loss: 0.304440  [51200/60000]\n",
            "loss: 0.283747  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.333854 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.166952  [    0/60000]\n",
            "loss: 0.225933  [ 6400/60000]\n",
            "loss: 0.159500  [12800/60000]\n",
            "loss: 0.214382  [19200/60000]\n",
            "loss: 0.242566  [25600/60000]\n",
            "loss: 0.276717  [32000/60000]\n",
            "loss: 0.225436  [38400/60000]\n",
            "loss: 0.243305  [44800/60000]\n",
            "loss: 0.301965  [51200/60000]\n",
            "loss: 0.279795  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.333329 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.168432  [    0/60000]\n",
            "loss: 0.222172  [ 6400/60000]\n",
            "loss: 0.159765  [12800/60000]\n",
            "loss: 0.211455  [19200/60000]\n",
            "loss: 0.242294  [25600/60000]\n",
            "loss: 0.274079  [32000/60000]\n",
            "loss: 0.223023  [38400/60000]\n",
            "loss: 0.238858  [44800/60000]\n",
            "loss: 0.297868  [51200/60000]\n",
            "loss: 0.273700  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.332495 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.161511  [    0/60000]\n",
            "loss: 0.220691  [ 6400/60000]\n",
            "loss: 0.160174  [12800/60000]\n",
            "loss: 0.208101  [19200/60000]\n",
            "loss: 0.238596  [25600/60000]\n",
            "loss: 0.270127  [32000/60000]\n",
            "loss: 0.221189  [38400/60000]\n",
            "loss: 0.234783  [44800/60000]\n",
            "loss: 0.292251  [51200/60000]\n",
            "loss: 0.269122  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.332039 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.164071  [    0/60000]\n",
            "loss: 0.219594  [ 6400/60000]\n",
            "loss: 0.159480  [12800/60000]\n",
            "loss: 0.206770  [19200/60000]\n",
            "loss: 0.235597  [25600/60000]\n",
            "loss: 0.264639  [32000/60000]\n",
            "loss: 0.219161  [38400/60000]\n",
            "loss: 0.231431  [44800/60000]\n",
            "loss: 0.288659  [51200/60000]\n",
            "loss: 0.265521  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.332502 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.167366  [    0/60000]\n",
            "loss: 0.214424  [ 6400/60000]\n",
            "loss: 0.157600  [12800/60000]\n",
            "loss: 0.202774  [19200/60000]\n",
            "loss: 0.233282  [25600/60000]\n",
            "loss: 0.265843  [32000/60000]\n",
            "loss: 0.216005  [38400/60000]\n",
            "loss: 0.227593  [44800/60000]\n",
            "loss: 0.286729  [51200/60000]\n",
            "loss: 0.264132  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.333938 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.168296  [    0/60000]\n",
            "loss: 0.211665  [ 6400/60000]\n",
            "loss: 0.156803  [12800/60000]\n",
            "loss: 0.200246  [19200/60000]\n",
            "loss: 0.234631  [25600/60000]\n",
            "loss: 0.263061  [32000/60000]\n",
            "loss: 0.211921  [38400/60000]\n",
            "loss: 0.223773  [44800/60000]\n",
            "loss: 0.280935  [51200/60000]\n",
            "loss: 0.261976  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.333004 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.164784  [    0/60000]\n",
            "loss: 0.210005  [ 6400/60000]\n",
            "loss: 0.156011  [12800/60000]\n",
            "loss: 0.197957  [19200/60000]\n",
            "loss: 0.229391  [25600/60000]\n",
            "loss: 0.260329  [32000/60000]\n",
            "loss: 0.209694  [38400/60000]\n",
            "loss: 0.221062  [44800/60000]\n",
            "loss: 0.278454  [51200/60000]\n",
            "loss: 0.257594  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.332626 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.165620  [    0/60000]\n",
            "loss: 0.207351  [ 6400/60000]\n",
            "loss: 0.153887  [12800/60000]\n",
            "loss: 0.195329  [19200/60000]\n",
            "loss: 0.225265  [25600/60000]\n",
            "loss: 0.258623  [32000/60000]\n",
            "loss: 0.208017  [38400/60000]\n",
            "loss: 0.220279  [44800/60000]\n",
            "loss: 0.274952  [51200/60000]\n",
            "loss: 0.255288  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.332389 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.161442  [    0/60000]\n",
            "loss: 0.203443  [ 6400/60000]\n",
            "loss: 0.151745  [12800/60000]\n",
            "loss: 0.192873  [19200/60000]\n",
            "loss: 0.222424  [25600/60000]\n",
            "loss: 0.257502  [32000/60000]\n",
            "loss: 0.205569  [38400/60000]\n",
            "loss: 0.214371  [44800/60000]\n",
            "loss: 0.269551  [51200/60000]\n",
            "loss: 0.251975  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.332092 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.161667  [    0/60000]\n",
            "loss: 0.202171  [ 6400/60000]\n",
            "loss: 0.149387  [12800/60000]\n",
            "loss: 0.189427  [19200/60000]\n",
            "loss: 0.221182  [25600/60000]\n",
            "loss: 0.254823  [32000/60000]\n",
            "loss: 0.203279  [38400/60000]\n",
            "loss: 0.211197  [44800/60000]\n",
            "loss: 0.266188  [51200/60000]\n",
            "loss: 0.247711  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.333557 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.166614  [    0/60000]\n",
            "loss: 0.200119  [ 6400/60000]\n",
            "loss: 0.147600  [12800/60000]\n",
            "loss: 0.186910  [19200/60000]\n",
            "loss: 0.217531  [25600/60000]\n",
            "loss: 0.253946  [32000/60000]\n",
            "loss: 0.200036  [38400/60000]\n",
            "loss: 0.208740  [44800/60000]\n",
            "loss: 0.263047  [51200/60000]\n",
            "loss: 0.245320  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.334545 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.166019  [    0/60000]\n",
            "loss: 0.196848  [ 6400/60000]\n",
            "loss: 0.146517  [12800/60000]\n",
            "loss: 0.182860  [19200/60000]\n",
            "loss: 0.216492  [25600/60000]\n",
            "loss: 0.251357  [32000/60000]\n",
            "loss: 0.196125  [38400/60000]\n",
            "loss: 0.202487  [44800/60000]\n",
            "loss: 0.257338  [51200/60000]\n",
            "loss: 0.245082  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.333973 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.166871  [    0/60000]\n",
            "loss: 0.193548  [ 6400/60000]\n",
            "loss: 0.144147  [12800/60000]\n",
            "loss: 0.182995  [19200/60000]\n",
            "loss: 0.215407  [25600/60000]\n",
            "loss: 0.249265  [32000/60000]\n",
            "loss: 0.196388  [38400/60000]\n",
            "loss: 0.199093  [44800/60000]\n",
            "loss: 0.255463  [51200/60000]\n",
            "loss: 0.242286  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.333275 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.162635  [    0/60000]\n",
            "loss: 0.190744  [ 6400/60000]\n",
            "loss: 0.142258  [12800/60000]\n",
            "loss: 0.180252  [19200/60000]\n",
            "loss: 0.212019  [25600/60000]\n",
            "loss: 0.247236  [32000/60000]\n",
            "loss: 0.193220  [38400/60000]\n",
            "loss: 0.194877  [44800/60000]\n",
            "loss: 0.252420  [51200/60000]\n",
            "loss: 0.240365  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.336197 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.169715  [    0/60000]\n",
            "loss: 0.187690  [ 6400/60000]\n",
            "loss: 0.140704  [12800/60000]\n",
            "loss: 0.178172  [19200/60000]\n",
            "loss: 0.209456  [25600/60000]\n",
            "loss: 0.245873  [32000/60000]\n",
            "loss: 0.190594  [38400/60000]\n",
            "loss: 0.194135  [44800/60000]\n",
            "loss: 0.247412  [51200/60000]\n",
            "loss: 0.236558  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.334052 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.164588  [    0/60000]\n",
            "loss: 0.184700  [ 6400/60000]\n",
            "loss: 0.139429  [12800/60000]\n",
            "loss: 0.175460  [19200/60000]\n",
            "loss: 0.206611  [25600/60000]\n",
            "loss: 0.242566  [32000/60000]\n",
            "loss: 0.188580  [38400/60000]\n",
            "loss: 0.189893  [44800/60000]\n",
            "loss: 0.246260  [51200/60000]\n",
            "loss: 0.231981  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.333992 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.161331  [    0/60000]\n",
            "loss: 0.181556  [ 6400/60000]\n",
            "loss: 0.138123  [12800/60000]\n",
            "loss: 0.174145  [19200/60000]\n",
            "loss: 0.202999  [25600/60000]\n",
            "loss: 0.242576  [32000/60000]\n",
            "loss: 0.187301  [38400/60000]\n",
            "loss: 0.187923  [44800/60000]\n",
            "loss: 0.240679  [51200/60000]\n",
            "loss: 0.229825  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.336456 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.169076  [    0/60000]\n",
            "loss: 0.182185  [ 6400/60000]\n",
            "loss: 0.138344  [12800/60000]\n",
            "loss: 0.172189  [19200/60000]\n",
            "loss: 0.202080  [25600/60000]\n",
            "loss: 0.240565  [32000/60000]\n",
            "loss: 0.184045  [38400/60000]\n",
            "loss: 0.183664  [44800/60000]\n",
            "loss: 0.237496  [51200/60000]\n",
            "loss: 0.225787  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.336944 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.166119  [    0/60000]\n",
            "loss: 0.176547  [ 6400/60000]\n",
            "loss: 0.136114  [12800/60000]\n",
            "loss: 0.172129  [19200/60000]\n",
            "loss: 0.199858  [25600/60000]\n",
            "loss: 0.239327  [32000/60000]\n",
            "loss: 0.183441  [38400/60000]\n",
            "loss: 0.180616  [44800/60000]\n",
            "loss: 0.236901  [51200/60000]\n",
            "loss: 0.224794  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.337293 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.162895  [    0/60000]\n",
            "loss: 0.174854  [ 6400/60000]\n",
            "loss: 0.133200  [12800/60000]\n",
            "loss: 0.168722  [19200/60000]\n",
            "loss: 0.197372  [25600/60000]\n",
            "loss: 0.238795  [32000/60000]\n",
            "loss: 0.181001  [38400/60000]\n",
            "loss: 0.177782  [44800/60000]\n",
            "loss: 0.232063  [51200/60000]\n",
            "loss: 0.220800  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.342067 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.166846  [    0/60000]\n",
            "loss: 0.173574  [ 6400/60000]\n",
            "loss: 0.131623  [12800/60000]\n",
            "loss: 0.167625  [19200/60000]\n",
            "loss: 0.192644  [25600/60000]\n",
            "loss: 0.237062  [32000/60000]\n",
            "loss: 0.179975  [38400/60000]\n",
            "loss: 0.176122  [44800/60000]\n",
            "loss: 0.227115  [51200/60000]\n",
            "loss: 0.216112  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.340793 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.164478  [    0/60000]\n",
            "loss: 0.168795  [ 6400/60000]\n",
            "loss: 0.129168  [12800/60000]\n",
            "loss: 0.167081  [19200/60000]\n",
            "loss: 0.190055  [25600/60000]\n",
            "loss: 0.235011  [32000/60000]\n",
            "loss: 0.178934  [38400/60000]\n",
            "loss: 0.169951  [44800/60000]\n",
            "loss: 0.225929  [51200/60000]\n",
            "loss: 0.211529  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.339741 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.161373  [    0/60000]\n",
            "loss: 0.169080  [ 6400/60000]\n",
            "loss: 0.127782  [12800/60000]\n",
            "loss: 0.162926  [19200/60000]\n",
            "loss: 0.190639  [25600/60000]\n",
            "loss: 0.231530  [32000/60000]\n",
            "loss: 0.176844  [38400/60000]\n",
            "loss: 0.168725  [44800/60000]\n",
            "loss: 0.221988  [51200/60000]\n",
            "loss: 0.209116  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.336479 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.156346  [    0/60000]\n",
            "loss: 0.165753  [ 6400/60000]\n",
            "loss: 0.125510  [12800/60000]\n",
            "loss: 0.161730  [19200/60000]\n",
            "loss: 0.186048  [25600/60000]\n",
            "loss: 0.230205  [32000/60000]\n",
            "loss: 0.175861  [38400/60000]\n",
            "loss: 0.166609  [44800/60000]\n",
            "loss: 0.214870  [51200/60000]\n",
            "loss: 0.205147  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.340102 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.158976  [    0/60000]\n",
            "loss: 0.163282  [ 6400/60000]\n",
            "loss: 0.123516  [12800/60000]\n",
            "loss: 0.160422  [19200/60000]\n",
            "loss: 0.186312  [25600/60000]\n",
            "loss: 0.229296  [32000/60000]\n",
            "loss: 0.172792  [38400/60000]\n",
            "loss: 0.162674  [44800/60000]\n",
            "loss: 0.215773  [51200/60000]\n",
            "loss: 0.203763  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.339533 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.155204  [    0/60000]\n",
            "loss: 0.159544  [ 6400/60000]\n",
            "loss: 0.121517  [12800/60000]\n",
            "loss: 0.158092  [19200/60000]\n",
            "loss: 0.180562  [25600/60000]\n",
            "loss: 0.226059  [32000/60000]\n",
            "loss: 0.173152  [38400/60000]\n",
            "loss: 0.157941  [44800/60000]\n",
            "loss: 0.212527  [51200/60000]\n",
            "loss: 0.202782  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.339684 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.152628  [    0/60000]\n",
            "loss: 0.158065  [ 6400/60000]\n",
            "loss: 0.118304  [12800/60000]\n",
            "loss: 0.156766  [19200/60000]\n",
            "loss: 0.178985  [25600/60000]\n",
            "loss: 0.225851  [32000/60000]\n",
            "loss: 0.171211  [38400/60000]\n",
            "loss: 0.152956  [44800/60000]\n",
            "loss: 0.211112  [51200/60000]\n",
            "loss: 0.198771  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.341481 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.155593  [    0/60000]\n",
            "loss: 0.155835  [ 6400/60000]\n",
            "loss: 0.118333  [12800/60000]\n",
            "loss: 0.154488  [19200/60000]\n",
            "loss: 0.174612  [25600/60000]\n",
            "loss: 0.220816  [32000/60000]\n",
            "loss: 0.170795  [38400/60000]\n",
            "loss: 0.148946  [44800/60000]\n",
            "loss: 0.206063  [51200/60000]\n",
            "loss: 0.194378  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.340516 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.152390  [    0/60000]\n",
            "loss: 0.153390  [ 6400/60000]\n",
            "loss: 0.117848  [12800/60000]\n",
            "loss: 0.153099  [19200/60000]\n",
            "loss: 0.172488  [25600/60000]\n",
            "loss: 0.222019  [32000/60000]\n",
            "loss: 0.167876  [38400/60000]\n",
            "loss: 0.155193  [44800/60000]\n",
            "loss: 0.205769  [51200/60000]\n",
            "loss: 0.192035  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.339622 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.147992  [    0/60000]\n",
            "loss: 0.151182  [ 6400/60000]\n",
            "loss: 0.116268  [12800/60000]\n",
            "loss: 0.147996  [19200/60000]\n",
            "loss: 0.170309  [25600/60000]\n",
            "loss: 0.220889  [32000/60000]\n",
            "loss: 0.168116  [38400/60000]\n",
            "loss: 0.152562  [44800/60000]\n",
            "loss: 0.203329  [51200/60000]\n",
            "loss: 0.188489  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.343969 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.151415  [    0/60000]\n",
            "loss: 0.150631  [ 6400/60000]\n",
            "loss: 0.110960  [12800/60000]\n",
            "loss: 0.147582  [19200/60000]\n",
            "loss: 0.166661  [25600/60000]\n",
            "loss: 0.220040  [32000/60000]\n",
            "loss: 0.166160  [38400/60000]\n",
            "loss: 0.151353  [44800/60000]\n",
            "loss: 0.197950  [51200/60000]\n",
            "loss: 0.185199  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.344904 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.150695  [    0/60000]\n",
            "loss: 0.146185  [ 6400/60000]\n",
            "loss: 0.109905  [12800/60000]\n",
            "loss: 0.146278  [19200/60000]\n",
            "loss: 0.162716  [25600/60000]\n",
            "loss: 0.215585  [32000/60000]\n",
            "loss: 0.163885  [38400/60000]\n",
            "loss: 0.143496  [44800/60000]\n",
            "loss: 0.196897  [51200/60000]\n",
            "loss: 0.183963  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.343055 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.147843  [    0/60000]\n",
            "loss: 0.144312  [ 6400/60000]\n",
            "loss: 0.110947  [12800/60000]\n",
            "loss: 0.143740  [19200/60000]\n",
            "loss: 0.162847  [25600/60000]\n",
            "loss: 0.214509  [32000/60000]\n",
            "loss: 0.162635  [38400/60000]\n",
            "loss: 0.145542  [44800/60000]\n",
            "loss: 0.193023  [51200/60000]\n",
            "loss: 0.180421  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.348922 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.149463  [    0/60000]\n",
            "loss: 0.141487  [ 6400/60000]\n",
            "loss: 0.107588  [12800/60000]\n",
            "loss: 0.141343  [19200/60000]\n",
            "loss: 0.159661  [25600/60000]\n",
            "loss: 0.215255  [32000/60000]\n",
            "loss: 0.160296  [38400/60000]\n",
            "loss: 0.136926  [44800/60000]\n",
            "loss: 0.188627  [51200/60000]\n",
            "loss: 0.177877  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.352299 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.153245  [    0/60000]\n",
            "loss: 0.138217  [ 6400/60000]\n",
            "loss: 0.108297  [12800/60000]\n",
            "loss: 0.139706  [19200/60000]\n",
            "loss: 0.157372  [25600/60000]\n",
            "loss: 0.214067  [32000/60000]\n",
            "loss: 0.160365  [38400/60000]\n",
            "loss: 0.133548  [44800/60000]\n",
            "loss: 0.187698  [51200/60000]\n",
            "loss: 0.177473  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.349293 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.145268  [    0/60000]\n",
            "loss: 0.137448  [ 6400/60000]\n",
            "loss: 0.105859  [12800/60000]\n",
            "loss: 0.138203  [19200/60000]\n",
            "loss: 0.153228  [25600/60000]\n",
            "loss: 0.212796  [32000/60000]\n",
            "loss: 0.156092  [38400/60000]\n",
            "loss: 0.131297  [44800/60000]\n",
            "loss: 0.182899  [51200/60000]\n",
            "loss: 0.174278  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.352486 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.144987  [    0/60000]\n",
            "loss: 0.136066  [ 6400/60000]\n",
            "loss: 0.103647  [12800/60000]\n",
            "loss: 0.135300  [19200/60000]\n",
            "loss: 0.152367  [25600/60000]\n",
            "loss: 0.212075  [32000/60000]\n",
            "loss: 0.156969  [38400/60000]\n",
            "loss: 0.130531  [44800/60000]\n",
            "loss: 0.177908  [51200/60000]\n",
            "loss: 0.173538  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.349940 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.136401  [    0/60000]\n",
            "loss: 0.134204  [ 6400/60000]\n",
            "loss: 0.102050  [12800/60000]\n",
            "loss: 0.135943  [19200/60000]\n",
            "loss: 0.148282  [25600/60000]\n",
            "loss: 0.210023  [32000/60000]\n",
            "loss: 0.152335  [38400/60000]\n",
            "loss: 0.126197  [44800/60000]\n",
            "loss: 0.175679  [51200/60000]\n",
            "loss: 0.172141  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.356565 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.144753  [    0/60000]\n",
            "loss: 0.130248  [ 6400/60000]\n",
            "loss: 0.102611  [12800/60000]\n",
            "loss: 0.133762  [19200/60000]\n",
            "loss: 0.144709  [25600/60000]\n",
            "loss: 0.205902  [32000/60000]\n",
            "loss: 0.151959  [38400/60000]\n",
            "loss: 0.122467  [44800/60000]\n",
            "loss: 0.176094  [51200/60000]\n",
            "loss: 0.168885  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.359160 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.141786  [    0/60000]\n",
            "loss: 0.125285  [ 6400/60000]\n",
            "loss: 0.097334  [12800/60000]\n",
            "loss: 0.130121  [19200/60000]\n",
            "loss: 0.145257  [25600/60000]\n",
            "loss: 0.208248  [32000/60000]\n",
            "loss: 0.151587  [38400/60000]\n",
            "loss: 0.120681  [44800/60000]\n",
            "loss: 0.173513  [51200/60000]\n",
            "loss: 0.164206  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.362476 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.147759  [    0/60000]\n",
            "loss: 0.122467  [ 6400/60000]\n",
            "loss: 0.100402  [12800/60000]\n",
            "loss: 0.130158  [19200/60000]\n",
            "loss: 0.138601  [25600/60000]\n",
            "loss: 0.206218  [32000/60000]\n",
            "loss: 0.147053  [38400/60000]\n",
            "loss: 0.121558  [44800/60000]\n",
            "loss: 0.167398  [51200/60000]\n",
            "loss: 0.167448  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.362661 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.140636  [    0/60000]\n",
            "loss: 0.119019  [ 6400/60000]\n",
            "loss: 0.098380  [12800/60000]\n",
            "loss: 0.129353  [19200/60000]\n",
            "loss: 0.135415  [25600/60000]\n",
            "loss: 0.206665  [32000/60000]\n",
            "loss: 0.143870  [38400/60000]\n",
            "loss: 0.115921  [44800/60000]\n",
            "loss: 0.165046  [51200/60000]\n",
            "loss: 0.165676  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.359197 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Train and test the model \n",
        "loss_fn, optimizer = sgd_optimizer(model, lr=0.01)\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "\n",
        "    # print(acc)\n",
        "    # print(train_loss)\n",
        "    # wandb.log({'train_loss': train_loss, 'test_loss': test_loss, 'acc': acc, 'mean_loss': mean_loss})\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the loss and accuracy\n",
        "plt.title(\"Loss and accuracy (lr=0.01)\")\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(test_loss_store, label='test')\n",
        "plt.plot(acc, label='acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()\n",
        "\n",
        "# plot the mean gradient loss\n",
        "plt.title(\"Mean gradient loss\")\n",
        "plt.plot(grads, label='mean_grad_loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "grads = []\n",
        "train_loss = []   \n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    loss_store = []\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # The gradients will be calculated after we call backwards.\n",
        "        val = []\n",
        "        for param in model.parameters():\n",
        "            val.append(param.detach().numpy())\n",
        "        for i in val:\n",
        "            temp = np.array(i)\n",
        "        grads.append(temp.mean())\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        # train_loss.append(loss.item())\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            loss_store.append(loss)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            \n",
        "    train_loss.append(np.mean(loss_store))\n",
        "\n",
        "acc = []\n",
        "test_loss_store = []\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            # X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    # store the loss\n",
        "    test_loss_store.append(test_loss)\n",
        "    correct /= size\n",
        "    acc.append(correct)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.132671  [    0/60000]\n",
            "loss: 0.389917  [ 6400/60000]\n",
            "loss: 0.410026  [12800/60000]\n",
            "loss: 0.351331  [19200/60000]\n",
            "loss: 0.428221  [25600/60000]\n",
            "loss: 0.378922  [32000/60000]\n",
            "loss: 0.267006  [38400/60000]\n",
            "loss: 0.386723  [44800/60000]\n",
            "loss: 0.421118  [51200/60000]\n",
            "loss: 0.374412  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.435140 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.269307  [    0/60000]\n",
            "loss: 0.242528  [ 6400/60000]\n",
            "loss: 0.269553  [12800/60000]\n",
            "loss: 0.276308  [19200/60000]\n",
            "loss: 0.326448  [25600/60000]\n",
            "loss: 0.338694  [32000/60000]\n",
            "loss: 0.228298  [38400/60000]\n",
            "loss: 0.354592  [44800/60000]\n",
            "loss: 0.356990  [51200/60000]\n",
            "loss: 0.406402  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.420060 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.253095  [    0/60000]\n",
            "loss: 0.225826  [ 6400/60000]\n",
            "loss: 0.192832  [12800/60000]\n",
            "loss: 0.237586  [19200/60000]\n",
            "loss: 0.298047  [25600/60000]\n",
            "loss: 0.318181  [32000/60000]\n",
            "loss: 0.224883  [38400/60000]\n",
            "loss: 0.292079  [44800/60000]\n",
            "loss: 0.332787  [51200/60000]\n",
            "loss: 0.401071  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.409238 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.248524  [    0/60000]\n",
            "loss: 0.218620  [ 6400/60000]\n",
            "loss: 0.176580  [12800/60000]\n",
            "loss: 0.231114  [19200/60000]\n",
            "loss: 0.284270  [25600/60000]\n",
            "loss: 0.320763  [32000/60000]\n",
            "loss: 0.208878  [38400/60000]\n",
            "loss: 0.260033  [44800/60000]\n",
            "loss: 0.291506  [51200/60000]\n",
            "loss: 0.324752  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.392859 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.221321  [    0/60000]\n",
            "loss: 0.212738  [ 6400/60000]\n",
            "loss: 0.155963  [12800/60000]\n",
            "loss: 0.218335  [19200/60000]\n",
            "loss: 0.263272  [25600/60000]\n",
            "loss: 0.305095  [32000/60000]\n",
            "loss: 0.187455  [38400/60000]\n",
            "loss: 0.242683  [44800/60000]\n",
            "loss: 0.283300  [51200/60000]\n",
            "loss: 0.287476  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.376771 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.197424  [    0/60000]\n",
            "loss: 0.193397  [ 6400/60000]\n",
            "loss: 0.148182  [12800/60000]\n",
            "loss: 0.213362  [19200/60000]\n",
            "loss: 0.277306  [25600/60000]\n",
            "loss: 0.305920  [32000/60000]\n",
            "loss: 0.182621  [38400/60000]\n",
            "loss: 0.252008  [44800/60000]\n",
            "loss: 0.281591  [51200/60000]\n",
            "loss: 0.293441  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.375640 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.187276  [    0/60000]\n",
            "loss: 0.186671  [ 6400/60000]\n",
            "loss: 0.138139  [12800/60000]\n",
            "loss: 0.192102  [19200/60000]\n",
            "loss: 0.262696  [25600/60000]\n",
            "loss: 0.288828  [32000/60000]\n",
            "loss: 0.193490  [38400/60000]\n",
            "loss: 0.215912  [44800/60000]\n",
            "loss: 0.263590  [51200/60000]\n",
            "loss: 0.254284  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.382634 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.183039  [    0/60000]\n",
            "loss: 0.170385  [ 6400/60000]\n",
            "loss: 0.128936  [12800/60000]\n",
            "loss: 0.188402  [19200/60000]\n",
            "loss: 0.255983  [25600/60000]\n",
            "loss: 0.282836  [32000/60000]\n",
            "loss: 0.170799  [38400/60000]\n",
            "loss: 0.215870  [44800/60000]\n",
            "loss: 0.254489  [51200/60000]\n",
            "loss: 0.273293  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.388328 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.154430  [    0/60000]\n",
            "loss: 0.159593  [ 6400/60000]\n",
            "loss: 0.129082  [12800/60000]\n",
            "loss: 0.171850  [19200/60000]\n",
            "loss: 0.255234  [25600/60000]\n",
            "loss: 0.276097  [32000/60000]\n",
            "loss: 0.167389  [38400/60000]\n",
            "loss: 0.230755  [44800/60000]\n",
            "loss: 0.232315  [51200/60000]\n",
            "loss: 0.259562  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.384626 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.161348  [    0/60000]\n",
            "loss: 0.156021  [ 6400/60000]\n",
            "loss: 0.124851  [12800/60000]\n",
            "loss: 0.169629  [19200/60000]\n",
            "loss: 0.226692  [25600/60000]\n",
            "loss: 0.256893  [32000/60000]\n",
            "loss: 0.165575  [38400/60000]\n",
            "loss: 0.212748  [44800/60000]\n",
            "loss: 0.211044  [51200/60000]\n",
            "loss: 0.217540  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.371342 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.142999  [    0/60000]\n",
            "loss: 0.160160  [ 6400/60000]\n",
            "loss: 0.116463  [12800/60000]\n",
            "loss: 0.143739  [19200/60000]\n",
            "loss: 0.228188  [25600/60000]\n",
            "loss: 0.253185  [32000/60000]\n",
            "loss: 0.164264  [38400/60000]\n",
            "loss: 0.210140  [44800/60000]\n",
            "loss: 0.225397  [51200/60000]\n",
            "loss: 0.193411  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.372554 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.134440  [    0/60000]\n",
            "loss: 0.139273  [ 6400/60000]\n",
            "loss: 0.108992  [12800/60000]\n",
            "loss: 0.139434  [19200/60000]\n",
            "loss: 0.231796  [25600/60000]\n",
            "loss: 0.234021  [32000/60000]\n",
            "loss: 0.168829  [38400/60000]\n",
            "loss: 0.195675  [44800/60000]\n",
            "loss: 0.224618  [51200/60000]\n",
            "loss: 0.196311  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.389533 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.149097  [    0/60000]\n",
            "loss: 0.144023  [ 6400/60000]\n",
            "loss: 0.102904  [12800/60000]\n",
            "loss: 0.134626  [19200/60000]\n",
            "loss: 0.222719  [25600/60000]\n",
            "loss: 0.210240  [32000/60000]\n",
            "loss: 0.162026  [38400/60000]\n",
            "loss: 0.194549  [44800/60000]\n",
            "loss: 0.205897  [51200/60000]\n",
            "loss: 0.205710  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.390162 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.130662  [    0/60000]\n",
            "loss: 0.131960  [ 6400/60000]\n",
            "loss: 0.109291  [12800/60000]\n",
            "loss: 0.115449  [19200/60000]\n",
            "loss: 0.215031  [25600/60000]\n",
            "loss: 0.216843  [32000/60000]\n",
            "loss: 0.149728  [38400/60000]\n",
            "loss: 0.162982  [44800/60000]\n",
            "loss: 0.228427  [51200/60000]\n",
            "loss: 0.176971  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.375411 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.133247  [    0/60000]\n",
            "loss: 0.127949  [ 6400/60000]\n",
            "loss: 0.101419  [12800/60000]\n",
            "loss: 0.113581  [19200/60000]\n",
            "loss: 0.204212  [25600/60000]\n",
            "loss: 0.208677  [32000/60000]\n",
            "loss: 0.130938  [38400/60000]\n",
            "loss: 0.166479  [44800/60000]\n",
            "loss: 0.221152  [51200/60000]\n",
            "loss: 0.192302  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.391848 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.097807  [    0/60000]\n",
            "loss: 0.126084  [ 6400/60000]\n",
            "loss: 0.097722  [12800/60000]\n",
            "loss: 0.099708  [19200/60000]\n",
            "loss: 0.197633  [25600/60000]\n",
            "loss: 0.198609  [32000/60000]\n",
            "loss: 0.151083  [38400/60000]\n",
            "loss: 0.174315  [44800/60000]\n",
            "loss: 0.191204  [51200/60000]\n",
            "loss: 0.184464  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.396509 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.125341  [    0/60000]\n",
            "loss: 0.103475  [ 6400/60000]\n",
            "loss: 0.082801  [12800/60000]\n",
            "loss: 0.087462  [19200/60000]\n",
            "loss: 0.196677  [25600/60000]\n",
            "loss: 0.182561  [32000/60000]\n",
            "loss: 0.120165  [38400/60000]\n",
            "loss: 0.143549  [44800/60000]\n",
            "loss: 0.208089  [51200/60000]\n",
            "loss: 0.198832  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.396491 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.115409  [    0/60000]\n",
            "loss: 0.099420  [ 6400/60000]\n",
            "loss: 0.090952  [12800/60000]\n",
            "loss: 0.087708  [19200/60000]\n",
            "loss: 0.181435  [25600/60000]\n",
            "loss: 0.189343  [32000/60000]\n",
            "loss: 0.135782  [38400/60000]\n",
            "loss: 0.140948  [44800/60000]\n",
            "loss: 0.185435  [51200/60000]\n",
            "loss: 0.151573  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.385799 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.107719  [    0/60000]\n",
            "loss: 0.089948  [ 6400/60000]\n",
            "loss: 0.071467  [12800/60000]\n",
            "loss: 0.075009  [19200/60000]\n",
            "loss: 0.189026  [25600/60000]\n",
            "loss: 0.179574  [32000/60000]\n",
            "loss: 0.142455  [38400/60000]\n",
            "loss: 0.131987  [44800/60000]\n",
            "loss: 0.186799  [51200/60000]\n",
            "loss: 0.172544  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.405783 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.098067  [    0/60000]\n",
            "loss: 0.106882  [ 6400/60000]\n",
            "loss: 0.089123  [12800/60000]\n",
            "loss: 0.085552  [19200/60000]\n",
            "loss: 0.163082  [25600/60000]\n",
            "loss: 0.160739  [32000/60000]\n",
            "loss: 0.155943  [38400/60000]\n",
            "loss: 0.110359  [44800/60000]\n",
            "loss: 0.200446  [51200/60000]\n",
            "loss: 0.166614  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.413665 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.100292  [    0/60000]\n",
            "loss: 0.080538  [ 6400/60000]\n",
            "loss: 0.075599  [12800/60000]\n",
            "loss: 0.064633  [19200/60000]\n",
            "loss: 0.160268  [25600/60000]\n",
            "loss: 0.157136  [32000/60000]\n",
            "loss: 0.170114  [38400/60000]\n",
            "loss: 0.115102  [44800/60000]\n",
            "loss: 0.176762  [51200/60000]\n",
            "loss: 0.125643  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.403375 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.099913  [    0/60000]\n",
            "loss: 0.119597  [ 6400/60000]\n",
            "loss: 0.073281  [12800/60000]\n",
            "loss: 0.070790  [19200/60000]\n",
            "loss: 0.145574  [25600/60000]\n",
            "loss: 0.150111  [32000/60000]\n",
            "loss: 0.127215  [38400/60000]\n",
            "loss: 0.100602  [44800/60000]\n",
            "loss: 0.175103  [51200/60000]\n",
            "loss: 0.157288  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.414898 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.086182  [    0/60000]\n",
            "loss: 0.100887  [ 6400/60000]\n",
            "loss: 0.060494  [12800/60000]\n",
            "loss: 0.084632  [19200/60000]\n",
            "loss: 0.134827  [25600/60000]\n",
            "loss: 0.144607  [32000/60000]\n",
            "loss: 0.099367  [38400/60000]\n",
            "loss: 0.119880  [44800/60000]\n",
            "loss: 0.149623  [51200/60000]\n",
            "loss: 0.134340  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.439476 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.070015  [    0/60000]\n",
            "loss: 0.069966  [ 6400/60000]\n",
            "loss: 0.062567  [12800/60000]\n",
            "loss: 0.064549  [19200/60000]\n",
            "loss: 0.127522  [25600/60000]\n",
            "loss: 0.129457  [32000/60000]\n",
            "loss: 0.119311  [38400/60000]\n",
            "loss: 0.093033  [44800/60000]\n",
            "loss: 0.159618  [51200/60000]\n",
            "loss: 0.158773  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.438514 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.068272  [    0/60000]\n",
            "loss: 0.095536  [ 6400/60000]\n",
            "loss: 0.051304  [12800/60000]\n",
            "loss: 0.079200  [19200/60000]\n",
            "loss: 0.114634  [25600/60000]\n",
            "loss: 0.125267  [32000/60000]\n",
            "loss: 0.107274  [38400/60000]\n",
            "loss: 0.062385  [44800/60000]\n",
            "loss: 0.135692  [51200/60000]\n",
            "loss: 0.112657  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.435722 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.084317  [    0/60000]\n",
            "loss: 0.075110  [ 6400/60000]\n",
            "loss: 0.078582  [12800/60000]\n",
            "loss: 0.090075  [19200/60000]\n",
            "loss: 0.116793  [25600/60000]\n",
            "loss: 0.099563  [32000/60000]\n",
            "loss: 0.099308  [38400/60000]\n",
            "loss: 0.076249  [44800/60000]\n",
            "loss: 0.153927  [51200/60000]\n",
            "loss: 0.088803  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.582397 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.203812  [    0/60000]\n",
            "loss: 0.080349  [ 6400/60000]\n",
            "loss: 0.043204  [12800/60000]\n",
            "loss: 0.062565  [19200/60000]\n",
            "loss: 0.099781  [25600/60000]\n",
            "loss: 0.121290  [32000/60000]\n",
            "loss: 0.076660  [38400/60000]\n",
            "loss: 0.047893  [44800/60000]\n",
            "loss: 0.176950  [51200/60000]\n",
            "loss: 0.159659  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.524456 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.201505  [    0/60000]\n",
            "loss: 0.065726  [ 6400/60000]\n",
            "loss: 0.064532  [12800/60000]\n",
            "loss: 0.078610  [19200/60000]\n",
            "loss: 0.077928  [25600/60000]\n",
            "loss: 0.107832  [32000/60000]\n",
            "loss: 0.061367  [38400/60000]\n",
            "loss: 0.060185  [44800/60000]\n",
            "loss: 0.153596  [51200/60000]\n",
            "loss: 0.119952  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.463079 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.048716  [    0/60000]\n",
            "loss: 0.048932  [ 6400/60000]\n",
            "loss: 0.064425  [12800/60000]\n",
            "loss: 0.059172  [19200/60000]\n",
            "loss: 0.077303  [25600/60000]\n",
            "loss: 0.083820  [32000/60000]\n",
            "loss: 0.090504  [38400/60000]\n",
            "loss: 0.044606  [44800/60000]\n",
            "loss: 0.098698  [51200/60000]\n",
            "loss: 0.167316  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.528660 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.065022  [    0/60000]\n",
            "loss: 0.080104  [ 6400/60000]\n",
            "loss: 0.047511  [12800/60000]\n",
            "loss: 0.059149  [19200/60000]\n",
            "loss: 0.095665  [25600/60000]\n",
            "loss: 0.085942  [32000/60000]\n",
            "loss: 0.089758  [38400/60000]\n",
            "loss: 0.061940  [44800/60000]\n",
            "loss: 0.160117  [51200/60000]\n",
            "loss: 0.074111  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.1%, Avg loss: 0.476966 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.043565  [    0/60000]\n",
            "loss: 0.082899  [ 6400/60000]\n",
            "loss: 0.035628  [12800/60000]\n",
            "loss: 0.062187  [19200/60000]\n",
            "loss: 0.124857  [25600/60000]\n",
            "loss: 0.080947  [32000/60000]\n",
            "loss: 0.159789  [38400/60000]\n",
            "loss: 0.059476  [44800/60000]\n",
            "loss: 0.129002  [51200/60000]\n",
            "loss: 0.104040  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.479481 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.057845  [    0/60000]\n",
            "loss: 0.053644  [ 6400/60000]\n",
            "loss: 0.038660  [12800/60000]\n",
            "loss: 0.171354  [19200/60000]\n",
            "loss: 0.093771  [25600/60000]\n",
            "loss: 0.124096  [32000/60000]\n",
            "loss: 0.030679  [38400/60000]\n",
            "loss: 0.045940  [44800/60000]\n",
            "loss: 0.111497  [51200/60000]\n",
            "loss: 0.121390  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.500192 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.046917  [    0/60000]\n",
            "loss: 0.055491  [ 6400/60000]\n",
            "loss: 0.043229  [12800/60000]\n",
            "loss: 0.082249  [19200/60000]\n",
            "loss: 0.081018  [25600/60000]\n",
            "loss: 0.101237  [32000/60000]\n",
            "loss: 0.122086  [38400/60000]\n",
            "loss: 0.039361  [44800/60000]\n",
            "loss: 0.136213  [51200/60000]\n",
            "loss: 0.069265  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.533524 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.108245  [    0/60000]\n",
            "loss: 0.035319  [ 6400/60000]\n",
            "loss: 0.061778  [12800/60000]\n",
            "loss: 0.056488  [19200/60000]\n",
            "loss: 0.071331  [25600/60000]\n",
            "loss: 0.078173  [32000/60000]\n",
            "loss: 0.059098  [38400/60000]\n",
            "loss: 0.039541  [44800/60000]\n",
            "loss: 0.072047  [51200/60000]\n",
            "loss: 0.110550  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.604224 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.151219  [    0/60000]\n",
            "loss: 0.047923  [ 6400/60000]\n",
            "loss: 0.044501  [12800/60000]\n",
            "loss: 0.161887  [19200/60000]\n",
            "loss: 0.089826  [25600/60000]\n",
            "loss: 0.084743  [32000/60000]\n",
            "loss: 0.044174  [38400/60000]\n",
            "loss: 0.034538  [44800/60000]\n",
            "loss: 0.070680  [51200/60000]\n",
            "loss: 0.064591  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.569402 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.146870  [    0/60000]\n",
            "loss: 0.036741  [ 6400/60000]\n",
            "loss: 0.092570  [12800/60000]\n",
            "loss: 0.046809  [19200/60000]\n",
            "loss: 0.059504  [25600/60000]\n",
            "loss: 0.058134  [32000/60000]\n",
            "loss: 0.067740  [38400/60000]\n",
            "loss: 0.033689  [44800/60000]\n",
            "loss: 0.067220  [51200/60000]\n",
            "loss: 0.129232  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.489855 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.082305  [    0/60000]\n",
            "loss: 0.073474  [ 6400/60000]\n",
            "loss: 0.044714  [12800/60000]\n",
            "loss: 0.052554  [19200/60000]\n",
            "loss: 0.067301  [25600/60000]\n",
            "loss: 0.090709  [32000/60000]\n",
            "loss: 0.041739  [38400/60000]\n",
            "loss: 0.028291  [44800/60000]\n",
            "loss: 0.055793  [51200/60000]\n",
            "loss: 0.058068  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.547273 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.091728  [    0/60000]\n",
            "loss: 0.080306  [ 6400/60000]\n",
            "loss: 0.042839  [12800/60000]\n",
            "loss: 0.045218  [19200/60000]\n",
            "loss: 0.053578  [25600/60000]\n",
            "loss: 0.048935  [32000/60000]\n",
            "loss: 0.045913  [38400/60000]\n",
            "loss: 0.038000  [44800/60000]\n",
            "loss: 0.070404  [51200/60000]\n",
            "loss: 0.071636  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.533850 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.075156  [    0/60000]\n",
            "loss: 0.055603  [ 6400/60000]\n",
            "loss: 0.051772  [12800/60000]\n",
            "loss: 0.056108  [19200/60000]\n",
            "loss: 0.083051  [25600/60000]\n",
            "loss: 0.054343  [32000/60000]\n",
            "loss: 0.037267  [38400/60000]\n",
            "loss: 0.056374  [44800/60000]\n",
            "loss: 0.138644  [51200/60000]\n",
            "loss: 0.047320  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.540787 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.064689  [    0/60000]\n",
            "loss: 0.026729  [ 6400/60000]\n",
            "loss: 0.062709  [12800/60000]\n",
            "loss: 0.080189  [19200/60000]\n",
            "loss: 0.049830  [25600/60000]\n",
            "loss: 0.053741  [32000/60000]\n",
            "loss: 0.054630  [38400/60000]\n",
            "loss: 0.068034  [44800/60000]\n",
            "loss: 0.173190  [51200/60000]\n",
            "loss: 0.037615  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.616682 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.156123  [    0/60000]\n",
            "loss: 0.052321  [ 6400/60000]\n",
            "loss: 0.059567  [12800/60000]\n",
            "loss: 0.030480  [19200/60000]\n",
            "loss: 0.138994  [25600/60000]\n",
            "loss: 0.071721  [32000/60000]\n",
            "loss: 0.045483  [38400/60000]\n",
            "loss: 0.025320  [44800/60000]\n",
            "loss: 0.085903  [51200/60000]\n",
            "loss: 0.072006  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.602949 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.033792  [    0/60000]\n",
            "loss: 0.050632  [ 6400/60000]\n",
            "loss: 0.054761  [12800/60000]\n",
            "loss: 0.043398  [19200/60000]\n",
            "loss: 0.051095  [25600/60000]\n",
            "loss: 0.048878  [32000/60000]\n",
            "loss: 0.027459  [38400/60000]\n",
            "loss: 0.039486  [44800/60000]\n",
            "loss: 0.069869  [51200/60000]\n",
            "loss: 0.084416  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.525111 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.044347  [    0/60000]\n",
            "loss: 0.041121  [ 6400/60000]\n",
            "loss: 0.041157  [12800/60000]\n",
            "loss: 0.044663  [19200/60000]\n",
            "loss: 0.052793  [25600/60000]\n",
            "loss: 0.049001  [32000/60000]\n",
            "loss: 0.044423  [38400/60000]\n",
            "loss: 0.080296  [44800/60000]\n",
            "loss: 0.070087  [51200/60000]\n",
            "loss: 0.033205  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.623881 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.058418  [    0/60000]\n",
            "loss: 0.034372  [ 6400/60000]\n",
            "loss: 0.057788  [12800/60000]\n",
            "loss: 0.043335  [19200/60000]\n",
            "loss: 0.060014  [25600/60000]\n",
            "loss: 0.064944  [32000/60000]\n",
            "loss: 0.062530  [38400/60000]\n",
            "loss: 0.031180  [44800/60000]\n",
            "loss: 0.062933  [51200/60000]\n",
            "loss: 0.037714  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.611360 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.235886  [    0/60000]\n",
            "loss: 0.028149  [ 6400/60000]\n",
            "loss: 0.024944  [12800/60000]\n",
            "loss: 0.026139  [19200/60000]\n",
            "loss: 0.108829  [25600/60000]\n",
            "loss: 0.053030  [32000/60000]\n",
            "loss: 0.030861  [38400/60000]\n",
            "loss: 0.025908  [44800/60000]\n",
            "loss: 0.032121  [51200/60000]\n",
            "loss: 0.022569  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.580365 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.060774  [    0/60000]\n",
            "loss: 0.022317  [ 6400/60000]\n",
            "loss: 0.027996  [12800/60000]\n",
            "loss: 0.063795  [19200/60000]\n",
            "loss: 0.088352  [25600/60000]\n",
            "loss: 0.038050  [32000/60000]\n",
            "loss: 0.014532  [38400/60000]\n",
            "loss: 0.029203  [44800/60000]\n",
            "loss: 0.064313  [51200/60000]\n",
            "loss: 0.026131  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.581757 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.070981  [    0/60000]\n",
            "loss: 0.027235  [ 6400/60000]\n",
            "loss: 0.045714  [12800/60000]\n",
            "loss: 0.072430  [19200/60000]\n",
            "loss: 0.037058  [25600/60000]\n",
            "loss: 0.026437  [32000/60000]\n",
            "loss: 0.044707  [38400/60000]\n",
            "loss: 0.032003  [44800/60000]\n",
            "loss: 0.037268  [51200/60000]\n",
            "loss: 0.040826  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.603582 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.050311  [    0/60000]\n",
            "loss: 0.036178  [ 6400/60000]\n",
            "loss: 0.044004  [12800/60000]\n",
            "loss: 0.040019  [19200/60000]\n",
            "loss: 0.038560  [25600/60000]\n",
            "loss: 0.036110  [32000/60000]\n",
            "loss: 0.055777  [38400/60000]\n",
            "loss: 0.023068  [44800/60000]\n",
            "loss: 0.098915  [51200/60000]\n",
            "loss: 0.076761  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.619789 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.061542  [    0/60000]\n",
            "loss: 0.021974  [ 6400/60000]\n",
            "loss: 0.038391  [12800/60000]\n",
            "loss: 0.037580  [19200/60000]\n",
            "loss: 0.107128  [25600/60000]\n",
            "loss: 0.037355  [32000/60000]\n",
            "loss: 0.021296  [38400/60000]\n",
            "loss: 0.082228  [44800/60000]\n",
            "loss: 0.034358  [51200/60000]\n",
            "loss: 0.099102  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.589421 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.078453  [    0/60000]\n",
            "loss: 0.037150  [ 6400/60000]\n",
            "loss: 0.064408  [12800/60000]\n",
            "loss: 0.040061  [19200/60000]\n",
            "loss: 0.044912  [25600/60000]\n",
            "loss: 0.035598  [32000/60000]\n",
            "loss: 0.033727  [38400/60000]\n",
            "loss: 0.058831  [44800/60000]\n",
            "loss: 0.075543  [51200/60000]\n",
            "loss: 0.020898  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.610626 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.048990  [    0/60000]\n",
            "loss: 0.092175  [ 6400/60000]\n",
            "loss: 0.032879  [12800/60000]\n",
            "loss: 0.022298  [19200/60000]\n",
            "loss: 0.052865  [25600/60000]\n",
            "loss: 0.039849  [32000/60000]\n",
            "loss: 0.023829  [38400/60000]\n",
            "loss: 0.082776  [44800/60000]\n",
            "loss: 0.030566  [51200/60000]\n",
            "loss: 0.063730  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.604980 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.065783  [    0/60000]\n",
            "loss: 0.016277  [ 6400/60000]\n",
            "loss: 0.017533  [12800/60000]\n",
            "loss: 0.039275  [19200/60000]\n",
            "loss: 0.040197  [25600/60000]\n",
            "loss: 0.069272  [32000/60000]\n",
            "loss: 0.031590  [38400/60000]\n",
            "loss: 0.013112  [44800/60000]\n",
            "loss: 0.031473  [51200/60000]\n",
            "loss: 0.016787  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.629196 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.046199  [    0/60000]\n",
            "loss: 0.006731  [ 6400/60000]\n",
            "loss: 0.018445  [12800/60000]\n",
            "loss: 0.044892  [19200/60000]\n",
            "loss: 0.036944  [25600/60000]\n",
            "loss: 0.038568  [32000/60000]\n",
            "loss: 0.023028  [38400/60000]\n",
            "loss: 0.039759  [44800/60000]\n",
            "loss: 0.010342  [51200/60000]\n",
            "loss: 0.029040  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.624281 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.050242  [    0/60000]\n",
            "loss: 0.009772  [ 6400/60000]\n",
            "loss: 0.019670  [12800/60000]\n",
            "loss: 0.041537  [19200/60000]\n",
            "loss: 0.104781  [25600/60000]\n",
            "loss: 0.036057  [32000/60000]\n",
            "loss: 0.029223  [38400/60000]\n",
            "loss: 0.011645  [44800/60000]\n",
            "loss: 0.102477  [51200/60000]\n",
            "loss: 0.027724  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.617983 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.056122  [    0/60000]\n",
            "loss: 0.011351  [ 6400/60000]\n",
            "loss: 0.043389  [12800/60000]\n",
            "loss: 0.021065  [19200/60000]\n",
            "loss: 0.035683  [25600/60000]\n",
            "loss: 0.050523  [32000/60000]\n",
            "loss: 0.064334  [38400/60000]\n",
            "loss: 0.028668  [44800/60000]\n",
            "loss: 0.015179  [51200/60000]\n",
            "loss: 0.019742  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.644560 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.048110  [    0/60000]\n",
            "loss: 0.014172  [ 6400/60000]\n",
            "loss: 0.023283  [12800/60000]\n",
            "loss: 0.027681  [19200/60000]\n",
            "loss: 0.055444  [25600/60000]\n",
            "loss: 0.029383  [32000/60000]\n",
            "loss: 0.011378  [38400/60000]\n",
            "loss: 0.015699  [44800/60000]\n",
            "loss: 0.012566  [51200/60000]\n",
            "loss: 0.013296  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.660708 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.049403  [    0/60000]\n",
            "loss: 0.017226  [ 6400/60000]\n",
            "loss: 0.027416  [12800/60000]\n",
            "loss: 0.047140  [19200/60000]\n",
            "loss: 0.034571  [25600/60000]\n",
            "loss: 0.029906  [32000/60000]\n",
            "loss: 0.020684  [38400/60000]\n",
            "loss: 0.014898  [44800/60000]\n",
            "loss: 0.118694  [51200/60000]\n",
            "loss: 0.082909  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.654326 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.028799  [    0/60000]\n",
            "loss: 0.027538  [ 6400/60000]\n",
            "loss: 0.030551  [12800/60000]\n",
            "loss: 0.021778  [19200/60000]\n",
            "loss: 0.073967  [25600/60000]\n",
            "loss: 0.045434  [32000/60000]\n",
            "loss: 0.029281  [38400/60000]\n",
            "loss: 0.028187  [44800/60000]\n",
            "loss: 0.038798  [51200/60000]\n",
            "loss: 0.079871  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.732650 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.107276  [    0/60000]\n",
            "loss: 0.016938  [ 6400/60000]\n",
            "loss: 0.013629  [12800/60000]\n",
            "loss: 0.069251  [19200/60000]\n",
            "loss: 0.018592  [25600/60000]\n",
            "loss: 0.027428  [32000/60000]\n",
            "loss: 0.010306  [38400/60000]\n",
            "loss: 0.069250  [44800/60000]\n",
            "loss: 0.040052  [51200/60000]\n",
            "loss: 0.032725  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.687310 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.062827  [    0/60000]\n",
            "loss: 0.025855  [ 6400/60000]\n",
            "loss: 0.034431  [12800/60000]\n",
            "loss: 0.027764  [19200/60000]\n",
            "loss: 0.017973  [25600/60000]\n",
            "loss: 0.033682  [32000/60000]\n",
            "loss: 0.007424  [38400/60000]\n",
            "loss: 0.011572  [44800/60000]\n",
            "loss: 0.006463  [51200/60000]\n",
            "loss: 0.059791  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.670580 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.054715  [    0/60000]\n",
            "loss: 0.022794  [ 6400/60000]\n",
            "loss: 0.050399  [12800/60000]\n",
            "loss: 0.017658  [19200/60000]\n",
            "loss: 0.039126  [25600/60000]\n",
            "loss: 0.045962  [32000/60000]\n",
            "loss: 0.013353  [38400/60000]\n",
            "loss: 0.041011  [44800/60000]\n",
            "loss: 0.008748  [51200/60000]\n",
            "loss: 0.025799  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.655380 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.044044  [    0/60000]\n",
            "loss: 0.016655  [ 6400/60000]\n",
            "loss: 0.007566  [12800/60000]\n",
            "loss: 0.025108  [19200/60000]\n",
            "loss: 0.042566  [25600/60000]\n",
            "loss: 0.041917  [32000/60000]\n",
            "loss: 0.055737  [38400/60000]\n",
            "loss: 0.014993  [44800/60000]\n",
            "loss: 0.037488  [51200/60000]\n",
            "loss: 0.005413  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.717664 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.051660  [    0/60000]\n",
            "loss: 0.008700  [ 6400/60000]\n",
            "loss: 0.052028  [12800/60000]\n",
            "loss: 0.103803  [19200/60000]\n",
            "loss: 0.044732  [25600/60000]\n",
            "loss: 0.066723  [32000/60000]\n",
            "loss: 0.011599  [38400/60000]\n",
            "loss: 0.027503  [44800/60000]\n",
            "loss: 0.029014  [51200/60000]\n",
            "loss: 0.008560  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.685794 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.045499  [    0/60000]\n",
            "loss: 0.007965  [ 6400/60000]\n",
            "loss: 0.058997  [12800/60000]\n",
            "loss: 0.140664  [19200/60000]\n",
            "loss: 0.105572  [25600/60000]\n",
            "loss: 0.044236  [32000/60000]\n",
            "loss: 0.018890  [38400/60000]\n",
            "loss: 0.024270  [44800/60000]\n",
            "loss: 0.005617  [51200/60000]\n",
            "loss: 0.007574  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.742369 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.096161  [    0/60000]\n",
            "loss: 0.007412  [ 6400/60000]\n",
            "loss: 0.048947  [12800/60000]\n",
            "loss: 0.008505  [19200/60000]\n",
            "loss: 0.012260  [25600/60000]\n",
            "loss: 0.025299  [32000/60000]\n",
            "loss: 0.011758  [38400/60000]\n",
            "loss: 0.027921  [44800/60000]\n",
            "loss: 0.004132  [51200/60000]\n",
            "loss: 0.023500  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.747562 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.035762  [    0/60000]\n",
            "loss: 0.027802  [ 6400/60000]\n",
            "loss: 0.019617  [12800/60000]\n",
            "loss: 0.015739  [19200/60000]\n",
            "loss: 0.059364  [25600/60000]\n",
            "loss: 0.018487  [32000/60000]\n",
            "loss: 0.010683  [38400/60000]\n",
            "loss: 0.047219  [44800/60000]\n",
            "loss: 0.038626  [51200/60000]\n",
            "loss: 0.057018  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.703962 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.103956  [    0/60000]\n",
            "loss: 0.014593  [ 6400/60000]\n",
            "loss: 0.047297  [12800/60000]\n",
            "loss: 0.023176  [19200/60000]\n",
            "loss: 0.013879  [25600/60000]\n",
            "loss: 0.026948  [32000/60000]\n",
            "loss: 0.028960  [38400/60000]\n",
            "loss: 0.031370  [44800/60000]\n",
            "loss: 0.059175  [51200/60000]\n",
            "loss: 0.038530  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.718672 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.044924  [    0/60000]\n",
            "loss: 0.015190  [ 6400/60000]\n",
            "loss: 0.071324  [12800/60000]\n",
            "loss: 0.018747  [19200/60000]\n",
            "loss: 0.044434  [25600/60000]\n",
            "loss: 0.027220  [32000/60000]\n",
            "loss: 0.010913  [38400/60000]\n",
            "loss: 0.021394  [44800/60000]\n",
            "loss: 0.015902  [51200/60000]\n",
            "loss: 0.014567  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.701681 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.041289  [    0/60000]\n",
            "loss: 0.012525  [ 6400/60000]\n",
            "loss: 0.012491  [12800/60000]\n",
            "loss: 0.013662  [19200/60000]\n",
            "loss: 0.037588  [25600/60000]\n",
            "loss: 0.026162  [32000/60000]\n",
            "loss: 0.021000  [38400/60000]\n",
            "loss: 0.016420  [44800/60000]\n",
            "loss: 0.013910  [51200/60000]\n",
            "loss: 0.091059  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.762381 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.075719  [    0/60000]\n",
            "loss: 0.013162  [ 6400/60000]\n",
            "loss: 0.074524  [12800/60000]\n",
            "loss: 0.015858  [19200/60000]\n",
            "loss: 0.021204  [25600/60000]\n",
            "loss: 0.031050  [32000/60000]\n",
            "loss: 0.015868  [38400/60000]\n",
            "loss: 0.021930  [44800/60000]\n",
            "loss: 0.052952  [51200/60000]\n",
            "loss: 0.057015  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.707482 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.031587  [    0/60000]\n",
            "loss: 0.029469  [ 6400/60000]\n",
            "loss: 0.003044  [12800/60000]\n",
            "loss: 0.044748  [19200/60000]\n",
            "loss: 0.016372  [25600/60000]\n",
            "loss: 0.012179  [32000/60000]\n",
            "loss: 0.005758  [38400/60000]\n",
            "loss: 0.005591  [44800/60000]\n",
            "loss: 0.051511  [51200/60000]\n",
            "loss: 0.008085  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.685019 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.024668  [    0/60000]\n",
            "loss: 0.006117  [ 6400/60000]\n",
            "loss: 0.009337  [12800/60000]\n",
            "loss: 0.033161  [19200/60000]\n",
            "loss: 0.040835  [25600/60000]\n",
            "loss: 0.047978  [32000/60000]\n",
            "loss: 0.029475  [38400/60000]\n",
            "loss: 0.088254  [44800/60000]\n",
            "loss: 0.002035  [51200/60000]\n",
            "loss: 0.005951  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.682959 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.025017  [    0/60000]\n",
            "loss: 0.097819  [ 6400/60000]\n",
            "loss: 0.012936  [12800/60000]\n",
            "loss: 0.024858  [19200/60000]\n",
            "loss: 0.024730  [25600/60000]\n",
            "loss: 0.037687  [32000/60000]\n",
            "loss: 0.010984  [38400/60000]\n",
            "loss: 0.058971  [44800/60000]\n",
            "loss: 0.003653  [51200/60000]\n",
            "loss: 0.025102  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.706814 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.036927  [    0/60000]\n",
            "loss: 0.039376  [ 6400/60000]\n",
            "loss: 0.032052  [12800/60000]\n",
            "loss: 0.014010  [19200/60000]\n",
            "loss: 0.023783  [25600/60000]\n",
            "loss: 0.046109  [32000/60000]\n",
            "loss: 0.136697  [38400/60000]\n",
            "loss: 0.023931  [44800/60000]\n",
            "loss: 0.025033  [51200/60000]\n",
            "loss: 0.004606  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.818015 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.157755  [    0/60000]\n",
            "loss: 0.045845  [ 6400/60000]\n",
            "loss: 0.029637  [12800/60000]\n",
            "loss: 0.016654  [19200/60000]\n",
            "loss: 0.009911  [25600/60000]\n",
            "loss: 0.071092  [32000/60000]\n",
            "loss: 0.006709  [38400/60000]\n",
            "loss: 0.016545  [44800/60000]\n",
            "loss: 0.014241  [51200/60000]\n",
            "loss: 0.051303  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.802964 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.042604  [    0/60000]\n",
            "loss: 0.033418  [ 6400/60000]\n",
            "loss: 0.008177  [12800/60000]\n",
            "loss: 0.011522  [19200/60000]\n",
            "loss: 0.013692  [25600/60000]\n",
            "loss: 0.015853  [32000/60000]\n",
            "loss: 0.008078  [38400/60000]\n",
            "loss: 0.023475  [44800/60000]\n",
            "loss: 0.032052  [51200/60000]\n",
            "loss: 0.018402  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.730893 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.050376  [    0/60000]\n",
            "loss: 0.009807  [ 6400/60000]\n",
            "loss: 0.169181  [12800/60000]\n",
            "loss: 0.019436  [19200/60000]\n",
            "loss: 0.066686  [25600/60000]\n",
            "loss: 0.026503  [32000/60000]\n",
            "loss: 0.012894  [38400/60000]\n",
            "loss: 0.015782  [44800/60000]\n",
            "loss: 0.006733  [51200/60000]\n",
            "loss: 0.073204  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.716864 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.040425  [    0/60000]\n",
            "loss: 0.045321  [ 6400/60000]\n",
            "loss: 0.024780  [12800/60000]\n",
            "loss: 0.023918  [19200/60000]\n",
            "loss: 0.096071  [25600/60000]\n",
            "loss: 0.082824  [32000/60000]\n",
            "loss: 0.138454  [38400/60000]\n",
            "loss: 0.065358  [44800/60000]\n",
            "loss: 0.018416  [51200/60000]\n",
            "loss: 0.008242  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.725314 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.050054  [    0/60000]\n",
            "loss: 0.010847  [ 6400/60000]\n",
            "loss: 0.019030  [12800/60000]\n",
            "loss: 0.031057  [19200/60000]\n",
            "loss: 0.016412  [25600/60000]\n",
            "loss: 0.039804  [32000/60000]\n",
            "loss: 0.004977  [38400/60000]\n",
            "loss: 0.017689  [44800/60000]\n",
            "loss: 0.009523  [51200/60000]\n",
            "loss: 0.010814  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.891975 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.108373  [    0/60000]\n",
            "loss: 0.021742  [ 6400/60000]\n",
            "loss: 0.024855  [12800/60000]\n",
            "loss: 0.003465  [19200/60000]\n",
            "loss: 0.022549  [25600/60000]\n",
            "loss: 0.021719  [32000/60000]\n",
            "loss: 0.005357  [38400/60000]\n",
            "loss: 0.007953  [44800/60000]\n",
            "loss: 0.023327  [51200/60000]\n",
            "loss: 0.006004  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.929152 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.150455  [    0/60000]\n",
            "loss: 0.009189  [ 6400/60000]\n",
            "loss: 0.013656  [12800/60000]\n",
            "loss: 0.012695  [19200/60000]\n",
            "loss: 0.015444  [25600/60000]\n",
            "loss: 0.035289  [32000/60000]\n",
            "loss: 0.040297  [38400/60000]\n",
            "loss: 0.012533  [44800/60000]\n",
            "loss: 0.021827  [51200/60000]\n",
            "loss: 0.007468  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.722622 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.028861  [    0/60000]\n",
            "loss: 0.066050  [ 6400/60000]\n",
            "loss: 0.053322  [12800/60000]\n",
            "loss: 0.017573  [19200/60000]\n",
            "loss: 0.101608  [25600/60000]\n",
            "loss: 0.050411  [32000/60000]\n",
            "loss: 0.003865  [38400/60000]\n",
            "loss: 0.005912  [44800/60000]\n",
            "loss: 0.004261  [51200/60000]\n",
            "loss: 0.069588  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.809479 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.252089  [    0/60000]\n",
            "loss: 0.068371  [ 6400/60000]\n",
            "loss: 0.026761  [12800/60000]\n",
            "loss: 0.058156  [19200/60000]\n",
            "loss: 0.012132  [25600/60000]\n",
            "loss: 0.024092  [32000/60000]\n",
            "loss: 0.079115  [38400/60000]\n",
            "loss: 0.057254  [44800/60000]\n",
            "loss: 0.106302  [51200/60000]\n",
            "loss: 0.010006  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.756945 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.033840  [    0/60000]\n",
            "loss: 0.020370  [ 6400/60000]\n",
            "loss: 0.037405  [12800/60000]\n",
            "loss: 0.030648  [19200/60000]\n",
            "loss: 0.026638  [25600/60000]\n",
            "loss: 0.016123  [32000/60000]\n",
            "loss: 0.004094  [38400/60000]\n",
            "loss: 0.048294  [44800/60000]\n",
            "loss: 0.001390  [51200/60000]\n",
            "loss: 0.012040  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.764985 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.035426  [    0/60000]\n",
            "loss: 0.027515  [ 6400/60000]\n",
            "loss: 0.029663  [12800/60000]\n",
            "loss: 0.021817  [19200/60000]\n",
            "loss: 0.021075  [25600/60000]\n",
            "loss: 0.030212  [32000/60000]\n",
            "loss: 0.006958  [38400/60000]\n",
            "loss: 0.014967  [44800/60000]\n",
            "loss: 0.017677  [51200/60000]\n",
            "loss: 0.008124  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.749246 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.018263  [    0/60000]\n",
            "loss: 0.006386  [ 6400/60000]\n",
            "loss: 0.003447  [12800/60000]\n",
            "loss: 0.020480  [19200/60000]\n",
            "loss: 0.014114  [25600/60000]\n",
            "loss: 0.020842  [32000/60000]\n",
            "loss: 0.022970  [38400/60000]\n",
            "loss: 0.013690  [44800/60000]\n",
            "loss: 0.018180  [51200/60000]\n",
            "loss: 0.025188  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.775557 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.071300  [    0/60000]\n",
            "loss: 0.007760  [ 6400/60000]\n",
            "loss: 0.003900  [12800/60000]\n",
            "loss: 0.012385  [19200/60000]\n",
            "loss: 0.013334  [25600/60000]\n",
            "loss: 0.010612  [32000/60000]\n",
            "loss: 0.003531  [38400/60000]\n",
            "loss: 0.023573  [44800/60000]\n",
            "loss: 0.040845  [51200/60000]\n",
            "loss: 0.012042  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.755313 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.026133  [    0/60000]\n",
            "loss: 0.047603  [ 6400/60000]\n",
            "loss: 0.036770  [12800/60000]\n",
            "loss: 0.012520  [19200/60000]\n",
            "loss: 0.009904  [25600/60000]\n",
            "loss: 0.039357  [32000/60000]\n",
            "loss: 0.003793  [38400/60000]\n",
            "loss: 0.006476  [44800/60000]\n",
            "loss: 0.034207  [51200/60000]\n",
            "loss: 0.010643  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.752314 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.041194  [    0/60000]\n",
            "loss: 0.020190  [ 6400/60000]\n",
            "loss: 0.003171  [12800/60000]\n",
            "loss: 0.015563  [19200/60000]\n",
            "loss: 0.044514  [25600/60000]\n",
            "loss: 0.012277  [32000/60000]\n",
            "loss: 0.021704  [38400/60000]\n",
            "loss: 0.002907  [44800/60000]\n",
            "loss: 0.001888  [51200/60000]\n",
            "loss: 0.036766  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.765373 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.037568  [    0/60000]\n",
            "loss: 0.008215  [ 6400/60000]\n",
            "loss: 0.002524  [12800/60000]\n",
            "loss: 0.006996  [19200/60000]\n",
            "loss: 0.025422  [25600/60000]\n",
            "loss: 0.032144  [32000/60000]\n",
            "loss: 0.002648  [38400/60000]\n",
            "loss: 0.010678  [44800/60000]\n",
            "loss: 0.002327  [51200/60000]\n",
            "loss: 0.015100  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.779759 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.029239  [    0/60000]\n",
            "loss: 0.004252  [ 6400/60000]\n",
            "loss: 0.003379  [12800/60000]\n",
            "loss: 0.004396  [19200/60000]\n",
            "loss: 0.009325  [25600/60000]\n",
            "loss: 0.013844  [32000/60000]\n",
            "loss: 0.002653  [38400/60000]\n",
            "loss: 0.029126  [44800/60000]\n",
            "loss: 0.005344  [51200/60000]\n",
            "loss: 0.004676  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.808608 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.036707  [    0/60000]\n",
            "loss: 0.008976  [ 6400/60000]\n",
            "loss: 0.006077  [12800/60000]\n",
            "loss: 0.005547  [19200/60000]\n",
            "loss: 0.005125  [25600/60000]\n",
            "loss: 0.007302  [32000/60000]\n",
            "loss: 0.004622  [38400/60000]\n",
            "loss: 0.006105  [44800/60000]\n",
            "loss: 0.007038  [51200/60000]\n",
            "loss: 0.020263  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.808624 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.031279  [    0/60000]\n",
            "loss: 0.008085  [ 6400/60000]\n",
            "loss: 0.003688  [12800/60000]\n",
            "loss: 0.008007  [19200/60000]\n",
            "loss: 0.010980  [25600/60000]\n",
            "loss: 0.020965  [32000/60000]\n",
            "loss: 0.006018  [38400/60000]\n",
            "loss: 0.003658  [44800/60000]\n",
            "loss: 0.009191  [51200/60000]\n",
            "loss: 0.014337  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.934881 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.264450  [    0/60000]\n",
            "loss: 0.009477  [ 6400/60000]\n",
            "loss: 0.008797  [12800/60000]\n",
            "loss: 0.009421  [19200/60000]\n",
            "loss: 0.031957  [25600/60000]\n",
            "loss: 0.034722  [32000/60000]\n",
            "loss: 0.051200  [38400/60000]\n",
            "loss: 0.007234  [44800/60000]\n",
            "loss: 0.017390  [51200/60000]\n",
            "loss: 0.004108  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.785489 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.026736  [    0/60000]\n",
            "loss: 0.006166  [ 6400/60000]\n",
            "loss: 0.001936  [12800/60000]\n",
            "loss: 0.008638  [19200/60000]\n",
            "loss: 0.022961  [25600/60000]\n",
            "loss: 0.008082  [32000/60000]\n",
            "loss: 0.011907  [38400/60000]\n",
            "loss: 0.001776  [44800/60000]\n",
            "loss: 0.012024  [51200/60000]\n",
            "loss: 0.007415  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.805611 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.010878  [    0/60000]\n",
            "loss: 0.017400  [ 6400/60000]\n",
            "loss: 0.001878  [12800/60000]\n",
            "loss: 0.010333  [19200/60000]\n",
            "loss: 0.029938  [25600/60000]\n",
            "loss: 0.009638  [32000/60000]\n",
            "loss: 0.285536  [38400/60000]\n",
            "loss: 0.026072  [44800/60000]\n",
            "loss: 0.063386  [51200/60000]\n",
            "loss: 0.029800  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.780613 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.031599  [    0/60000]\n",
            "loss: 0.010185  [ 6400/60000]\n",
            "loss: 0.008026  [12800/60000]\n",
            "loss: 0.072594  [19200/60000]\n",
            "loss: 0.037182  [25600/60000]\n",
            "loss: 0.014567  [32000/60000]\n",
            "loss: 0.029747  [38400/60000]\n",
            "loss: 0.010379  [44800/60000]\n",
            "loss: 0.024986  [51200/60000]\n",
            "loss: 0.138831  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.777662 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.007571  [    0/60000]\n",
            "loss: 0.017279  [ 6400/60000]\n",
            "loss: 0.001142  [12800/60000]\n",
            "loss: 0.006066  [19200/60000]\n",
            "loss: 0.015459  [25600/60000]\n",
            "loss: 0.037455  [32000/60000]\n",
            "loss: 0.002058  [38400/60000]\n",
            "loss: 0.003275  [44800/60000]\n",
            "loss: 0.021609  [51200/60000]\n",
            "loss: 0.009265  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.792147 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.018010  [    0/60000]\n",
            "loss: 0.002925  [ 6400/60000]\n",
            "loss: 0.008057  [12800/60000]\n",
            "loss: 0.038285  [19200/60000]\n",
            "loss: 0.011756  [25600/60000]\n",
            "loss: 0.013351  [32000/60000]\n",
            "loss: 0.004318  [38400/60000]\n",
            "loss: 0.003855  [44800/60000]\n",
            "loss: 0.001129  [51200/60000]\n",
            "loss: 0.014481  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.889433 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.012070  [    0/60000]\n",
            "loss: 0.086460  [ 6400/60000]\n",
            "loss: 0.021213  [12800/60000]\n",
            "loss: 0.008068  [19200/60000]\n",
            "loss: 0.034537  [25600/60000]\n",
            "loss: 0.007480  [32000/60000]\n",
            "loss: 0.004489  [38400/60000]\n",
            "loss: 0.006479  [44800/60000]\n",
            "loss: 0.003738  [51200/60000]\n",
            "loss: 0.068029  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.779397 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Train and test the model \n",
        "loss_fn, optimizer = sgd_optimizer(model, lr=0.1)\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "\n",
        "    # print(acc)\n",
        "    # print(train_loss)\n",
        "    # wandb.log({'train_loss': train_loss, 'test_loss': test_loss, 'acc': acc, 'mean_loss': mean_loss})\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the loss and accuracy\n",
        "plt.title(\"Loss and accuracy (lr=0.1)\")\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(test_loss_store, label='test')\n",
        "plt.plot(acc, label='acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()\n",
        "\n",
        "# plot the mean gradient loss\n",
        "plt.title(\"Mean gradient loss\")\n",
        "plt.plot(grads, label='mean_grad_loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S16_96RS3O1H"
      },
      "source": [
        "# Question 2: Proposal for Practical Applications (40%)\n",
        "Look for a typical computer vision problem, such as:\n",
        "a. removing noise on the image\n",
        "\n",
        "b. increasing the resolution of the image\n",
        "\n",
        "c. identifying objects in the image\n",
        "\n",
        "d. segmenting the area to which the image belongs\n",
        "\n",
        "e. estimating the depth of an object\n",
        "\n",
        "f. estimating the motion of two object in different frames\n",
        "\n",
        "h. others\n",
        "\n",
        "Discuss possible applications of this problem in life, e.g. image editing systems in your phone, improved quality of the old film, sweeping robot avoiding obstacles, unlocks the face of the mobile phone, identifies the cancer area according to the medical scan image, determines the identity according to the face, identifies the trash can on the road, and the detection system tracks the target object, etc.\n",
        "\n",
        "In this question, you need to do\n",
        "1. Clearly define the problem and describe its application scenarios\n",
        "2. Briefly describe a feasible solution based on image processing and traditional machine learning algorithms.\n",
        "3. Briefly describe a feasible deep learning-based solution.\n",
        "4. Compare the advantages and disadvantages of the two options.\n",
        "\n",
        "Hint1: Submit an individua report for question 2.\n",
        "\n",
        "Hint2: Well orginaze your report.\n",
        "\n",
        "Hint3: You can draw flow chart or inculde other figures for better understanding of your solution.  \n",
        "\n",
        "Please restrict your report within 800 words. In this question, you do not need to implement your solution. You only need to write down a proposal. Please submit this report in a seperate pdf. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "a3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
