Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])
Shape of y:  torch.Size([64]) torch.int64
Using cpu device
  401408
     512
  262144
     512
    5120
      10
________
  669706
Epoch 1
-------------------------------
loss: 2.318883  [    0/60000]
loss: 2.171308  [ 6400/60000]
loss: 2.077137  [12800/60000]
loss: 1.646823  [19200/60000]
loss: 1.786750  [25600/60000]
loss: 1.535509  [32000/60000]
loss: 1.889895  [38400/60000]
loss: 1.695297  [44800/60000]
loss: 1.723885  [51200/60000]
loss: 1.695694  [57600/60000]
Test Error:
 Accuracy: 19.9%, Avg loss: 1.736612
Epoch 2
-------------------------------
loss: 1.723631  [    0/60000]
loss: 1.694830  [ 6400/60000]
loss: 1.748595  [12800/60000]
loss: 1.972443  [19200/60000]
loss: 1.664000  [25600/60000]
loss: 1.776297  [32000/60000]
loss: 1.657663  [38400/60000]
loss: 1.824061  [44800/60000]
loss: 1.684113  [51200/60000]
loss: 1.806104  [57600/60000]
Test Error:
 Accuracy: 19.6%, Avg loss: 1.743750
Epoch 3
-------------------------------
loss: 1.785598  [    0/60000]
loss: 1.685836  [ 6400/60000]
loss: 1.741643  [12800/60000]
loss: 1.727027  [19200/60000]
loss: 1.659142  [25600/60000]
loss: 1.732147  [32000/60000]
loss: 1.538755  [38400/60000]
loss: 1.696394  [44800/60000]
loss: 1.730108  [51200/60000]
loss: 1.760174  [57600/60000]
Test Error:
 Accuracy: 19.6%, Avg loss: 1.753078
Epoch 4
-------------------------------
loss: 1.869125  [    0/60000]
loss: 1.689212  [ 6400/60000]
loss: 1.740144  [12800/60000]
loss: 1.810897  [19200/60000]
loss: 1.648589  [25600/60000]
loss: 1.735910  [32000/60000]
loss: 1.747087  [38400/60000]
loss: 1.673684  [44800/60000]
loss: 1.726218  [51200/60000]
loss: 2.378438  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.326029
Epoch 5
-------------------------------
loss: 2.244423  [    0/60000]
loss: 2.315112  [ 6400/60000]
loss: 2.332578  [12800/60000]
loss: 2.311771  [19200/60000]
loss: 3.471783  [25600/60000]
loss: 2.303968  [32000/60000]
loss: 2.305944  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 6
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 7
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 8
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 9
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 10
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 11
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 12
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 13
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 14
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 15
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 16
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
loss: 2.281377  [25600/60000]
loss: 2.304950  [32000/60000]
loss: 2.305945  [38400/60000]
loss: 2.288610  [44800/60000]
loss: 2.300421  [51200/60000]
loss: 2.330204  [57600/60000]
Test Error:
 Accuracy: 10.0%, Avg loss: 2.305845
Epoch 17
-------------------------------
loss: 2.296562  [    0/60000]
loss: 2.306795  [ 6400/60000]
loss: 2.312776  [12800/60000]
loss: 2.304621  [19200/60000]
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.