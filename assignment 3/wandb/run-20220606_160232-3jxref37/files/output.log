Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])
Shape of y:  torch.Size([64]) torch.int64
Using cpu device
  401408
     512
  262144
     512
    5120
      10
________
  669706
Epoch 1
-------------------------------
loss: 2.295359  [    0/60000]
loss: 2.289514  [ 6400/60000]
loss: 2.269325  [12800/60000]
loss: 2.273550  [19200/60000]
loss: 2.250312  [25600/60000]
loss: 2.221755  [32000/60000]
loss: 2.240273  [38400/60000]
loss: 2.198109  [44800/60000]
loss: 2.199154  [51200/60000]
loss: 2.175951  [57600/60000]
Test Error:
 Accuracy: 43.9%, Avg loss: 2.160098
Epoch 2
-------------------------------
loss: 2.134394  [    0/60000]
loss: 2.127117  [ 6400/60000]
loss: 2.057416  [12800/60000]
loss: 2.086254  [19200/60000]
loss: 2.022288  [25600/60000]
loss: 1.963022  [32000/60000]
loss: 2.006235  [38400/60000]
loss: 1.914293  [44800/60000]
loss: 1.919005  [51200/60000]
loss: 1.852779  [57600/60000]
Test Error:
 Accuracy: 61.5%, Avg loss: 1.835467
Epoch 3
-------------------------------
loss: 1.810491  [    0/60000]
loss: 1.774142  [ 6400/60000]
loss: 1.631474  [12800/60000]
loss: 1.692572  [19200/60000]
loss: 1.564006  [25600/60000]
loss: 1.533828  [32000/60000]
loss: 1.566164  [38400/60000]
loss: 1.466323  [44800/60000]
loss: 1.491588  [51200/60000]
loss: 1.391545  [57600/60000]
Test Error:
 Accuracy: 63.5%, Avg loss: 1.403915
Epoch 4
-------------------------------
loss: 1.432875  [    0/60000]
loss: 1.404842  [ 6400/60000]
loss: 1.235904  [12800/60000]
loss: 1.333342  [19200/60000]
loss: 1.200951  [25600/60000]
loss: 1.218742  [32000/60000]
loss: 1.243894  [38400/60000]
loss: 1.172017  [44800/60000]
loss: 1.210658  [51200/60000]
loss: 1.123483  [57600/60000]
Test Error:
 Accuracy: 64.5%, Avg loss: 1.142444
Epoch 5
-------------------------------
loss: 1.193317  [    0/60000]
loss: 1.189896  [ 6400/60000]
loss: 1.003124  [12800/60000]
loss: 1.141181  [19200/60000]
loss: 1.004196  [25600/60000]
loss: 1.037603  [32000/60000]
loss: 1.076287  [38400/60000]
loss: 1.011303  [44800/60000]
loss: 1.053270  [51200/60000]
loss: 0.987270  [57600/60000]
Test Error:
 Accuracy: 65.7%, Avg loss: 0.998483
Epoch 6
-------------------------------
loss: 1.046333  [    0/60000]
loss: 1.067635  [ 6400/60000]
loss: 0.860604  [12800/60000]
loss: 1.030812  [19200/60000]
loss: 0.896306  [25600/60000]
loss: 0.923350  [32000/60000]
loss: 0.980425  [38400/60000]
loss: 0.917109  [44800/60000]
loss: 0.954866  [51200/60000]
loss: 0.906259  [57600/60000]
Test Error:
 Accuracy: 67.1%, Avg loss: 0.910142
Epoch 7
-------------------------------
loss: 0.946267  [    0/60000]
loss: 0.989212  [ 6400/60000]
loss: 0.765229  [12800/60000]
loss: 0.958474  [19200/60000]
loss: 0.830143  [25600/60000]
loss: 0.844497  [32000/60000]
loss: 0.917956  [38400/60000]
loss: 0.857870  [44800/60000]
loss: 0.887892  [51200/60000]
loss: 0.851294  [57600/60000]
Test Error:
 Accuracy: 68.7%, Avg loss: 0.850183
Epoch 8
-------------------------------
loss: 0.872215  [    0/60000]
loss: 0.932489  [ 6400/60000]
loss: 0.697033  [12800/60000]
loss: 0.906501  [19200/60000]
loss: 0.785268  [25600/60000]
loss: 0.787843  [32000/60000]
loss: 0.871990  [38400/60000]
loss: 0.818286  [44800/60000]
loss: 0.839976  [51200/60000]
loss: 0.810422  [57600/60000]
Test Error:
 Accuracy: 70.2%, Avg loss: 0.806192
Epoch 9
-------------------------------
loss: 0.814481  [    0/60000]
loss: 0.887371  [ 6400/60000]
loss: 0.645820  [12800/60000]
loss: 0.866804  [19200/60000]
loss: 0.751889  [25600/60000]
loss: 0.745740  [32000/60000]
loss: 0.834772  [38400/60000]
loss: 0.789713  [44800/60000]
loss: 0.803729  [51200/60000]
loss: 0.777954  [57600/60000]
Test Error:
 Accuracy: 71.6%, Avg loss: 0.771800
Epoch 10
-------------------------------
loss: 0.767678  [    0/60000]
loss: 0.849401  [ 6400/60000]
loss: 0.605510  [12800/60000]
loss: 0.835401  [19200/60000]
loss: 0.725387  [25600/60000]
loss: 0.713683  [32000/60000]
loss: 0.802725  [38400/60000]
loss: 0.767162  [44800/60000]
loss: 0.774806  [51200/60000]
loss: 0.750730  [57600/60000]
Test Error:
 Accuracy: 73.0%, Avg loss: 0.743376
Epoch 11
-------------------------------
loss: 0.728324  [    0/60000]
loss: 0.816125  [ 6400/60000]
loss: 0.572734  [12800/60000]
loss: 0.809756  [19200/60000]
loss: 0.703563  [25600/60000]
loss: 0.688477  [32000/60000]
loss: 0.774308  [38400/60000]
loss: 0.748350  [44800/60000]
loss: 0.750814  [51200/60000]
loss: 0.727188  [57600/60000]
Test Error:
 Accuracy: 74.3%, Avg loss: 0.718979
Epoch 12
-------------------------------
loss: 0.694743  [    0/60000]
loss: 0.786338  [ 6400/60000]
loss: 0.545147  [12800/60000]
loss: 0.788009  [19200/60000]
loss: 0.684855  [25600/60000]
loss: 0.668089  [32000/60000]
loss: 0.748577  [38400/60000]
loss: 0.732084  [44800/60000]
loss: 0.730729  [51200/60000]
loss: 0.706395  [57600/60000]
Test Error:
 Accuracy: 75.2%, Avg loss: 0.697534
Epoch 13
-------------------------------
loss: 0.665993  [    0/60000]
loss: 0.759507  [ 6400/60000]
loss: 0.521529  [12800/60000]
loss: 0.769102  [19200/60000]
loss: 0.668720  [25600/60000]
loss: 0.651275  [32000/60000]
loss: 0.725055  [38400/60000]
loss: 0.717871  [44800/60000]
loss: 0.713549  [51200/60000]
loss: 0.687702  [57600/60000]
Test Error:
 Accuracy: 76.0%, Avg loss: 0.678400
Epoch 14
-------------------------------
loss: 0.640932  [    0/60000]
loss: 0.735507  [ 6400/60000]
loss: 0.501054  [12800/60000]
loss: 0.752386  [19200/60000]
loss: 0.654558  [25600/60000]
loss: 0.637302  [32000/60000]
loss: 0.703634  [38400/60000]
loss: 0.705376  [44800/60000]
loss: 0.698870  [51200/60000]
loss: 0.670750  [57600/60000]
Test Error:
 Accuracy: 76.8%, Avg loss: 0.661192
Epoch 15
-------------------------------
loss: 0.618865  [    0/60000]
loss: 0.713924  [ 6400/60000]
loss: 0.483137  [12800/60000]
loss: 0.737262  [19200/60000]
loss: 0.642095  [25600/60000]
loss: 0.625372  [32000/60000]
loss: 0.684102  [38400/60000]
loss: 0.694541  [44800/60000]
loss: 0.686326  [51200/60000]
loss: 0.655368  [57600/60000]
Test Error:
 Accuracy: 77.5%, Avg loss: 0.645667
Epoch 16
-------------------------------
loss: 0.599245  [    0/60000]
loss: 0.694455  [ 6400/60000]
loss: 0.467407  [12800/60000]
loss: 0.723527  [19200/60000]
loss: 0.631057  [25600/60000]
loss: 0.615032  [32000/60000]
loss: 0.666258  [38400/60000]
loss: 0.685378  [44800/60000]
loss: 0.675715  [51200/60000]
loss: 0.641363  [57600/60000]
Test Error:
 Accuracy: 78.0%, Avg loss: 0.631636
Epoch 17
-------------------------------
loss: 0.581714  [    0/60000]
loss: 0.676963  [ 6400/60000]
loss: 0.453389  [12800/60000]
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.